{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import pickle \n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "ps = PorterStemmer() \n",
    "spell = Speller()\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(os.getcwd(), \"ch02-train\")\n",
    "filenames_train = os.listdir(path_train)\n",
    "\n",
    "data = OrderedDict()\n",
    "labels = []\n",
    "for filename in filenames_train:\n",
    "    with open(os.path.join(os.getcwd(), \"ch02-train\", filename), mode = 'r', encoding = 'latin-1') as f:\n",
    "        try:\n",
    "            data[filename] = f.read()\n",
    "            labels.append(filename[-1])\n",
    "        except UnicodeDecodeError as error:\n",
    "            print(filename, \"   \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.path.join(os.getcwd(), \"ch02-test\")\n",
    "filenames_test = os.listdir(path_test)\n",
    "\n",
    "test = OrderedDict()\n",
    "for filename in filenames_test:\n",
    "    with open(os.path.join(os.getcwd(), \"ch02-test\", filename), mode = 'r', encoding = 'latin-1') as f:\n",
    "        try:\n",
    "            test[filename] = f.read()\n",
    "        except UnicodeDecodeError as error:\n",
    "            print(filename, \"   \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ise(text):\n",
    "    text = nltk.re.sub('[^A-Za-z]', ' ', text).lower()\n",
    "    tokens = nltk.re.sub(' +', ' ', text).strip().split(\" \")\n",
    "#     tokens = [ps.stem(spell(word)) for word in tokens]  # with spellcheck the function takes forever\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    \n",
    "    clear_tokens = [token for token in tokens if token not in stop]\n",
    "    \n",
    "    return \" \".join(clear_tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_data = Parallel(n_jobs = -1)(delayed(token_ise)(example) for example in data.values())\n",
    "tokenized_test = Parallel(n_jobs = -1)(delayed(token_ise)(example) for example in test.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   17.1s remaining:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:   23.4s remaining:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   26.5s finished\n",
      "c:\\users\\m\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.0001, 0.0005, 0.001, 0.005, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(balanced_accuracy_score), verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_opt = CountVectorizer(stop_words = stop)\n",
    "X_train_transformed = vectorizer_opt.fit_transform(tokenized_data)\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.0005, 0.001, 0.005, 0.01]}  \n",
    "grid = GridSearchCV(LinearSVC(), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring= make_scorer(balanced_accuracy_score)) \n",
    "  \n",
    "grid.fit(X_train_transformed, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0005, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998279878191938"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_test = CountVectorizer(stop_words = stop)\n",
    "\n",
    "X_train = vectorizer_test.fit_transform(tokenized_data)\n",
    "X_test = vectorizer_test.transform(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_test = LinearSVC(C = 0.005)  # value from the grid search best C\n",
    "\n",
    "svc_test.fit(X_train, labels)\n",
    "predictions_test = svc_test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.Series(predictions_test, index = test.keys()).to_csv(\"pred_of_test_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
