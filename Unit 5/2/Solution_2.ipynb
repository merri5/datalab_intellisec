{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "def Network():\n",
    "    network = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        \n",
    "    \n",
    "        \n",
    "        nn.Conv2d(16, 16, 4, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        \n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 4, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(32, 64, 4, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        Flatten(),\n",
    "        nn.Linear(64*6*6,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    "    return network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Network_Digits():\n",
    "    network = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        \n",
    "    \n",
    "        nn.Conv2d(16, 16, 4, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        \n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 4, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(32, 64, 4, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        \n",
    "        Flatten(),\n",
    "        nn.Linear(64*6*6,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train(path_benign, filenames_benign, path_adversarial, filenames_adversarial):\n",
    "    '''For the classifier for digit n, all inputs from the benign data that are '.n' are with label 0.\n",
    "        All the other inputs from the benign dataset, as well as all inputs from the adversarial datasat have label 1'''\n",
    "    \n",
    "    my_x = []\n",
    "    my_y_np_0 = np.array([])\n",
    "    my_y_np_1 = np.array([])\n",
    "    my_y_np_2 = np.array([])\n",
    "    my_y_np_3 = np.array([])\n",
    "    my_y_np_4 = np.array([])\n",
    "    my_y_np_5 = np.array([])\n",
    "    my_y_np_6 = np.array([])\n",
    "    my_y_np_7 = np.array([])\n",
    "    my_y_np_8 = np.array([])\n",
    "    my_y_np_9 = np.array([])\n",
    "    \n",
    "    for filename in filenames_benign:\n",
    "        my_x.append(cv2.imread(os.path.join(path_benign, filename), 0))\n",
    "        pre, ext = os.path.splitext(os.path.join(path_benign, filename))\n",
    "    \n",
    "    \n",
    "        if(np.array(ext[1:]).astype(np.uint8) == np.array(0).astype(np.uint8)):\n",
    "            my_y_np_0 = np.append(my_y_np_0,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_0 = np.append(my_y_np_0,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(1).astype(np.uint8)):   \n",
    "            my_y_np_1 = np.append(my_y_np_1,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_1 = np.append(my_y_np_1,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(2).astype(np.uint8)):   \n",
    "            my_y_np_2 = np.append(my_y_np_2,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_2 = np.append(my_y_np_2,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(3).astype(np.uint8)):   \n",
    "            my_y_np_3 = np.append(my_y_np_3,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_3 = np.append(my_y_np_3,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(4).astype(np.uint8)):   \n",
    "            my_y_np_4 = np.append(my_y_np_4,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_4 = np.append(my_y_np_4,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(5).astype(np.uint8)):   \n",
    "            my_y_np_5 = np.append(my_y_np_5,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_5 = np.append(my_y_np_5,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(6).astype(np.uint8)):   \n",
    "            my_y_np_6 = np.append(my_y_np_6,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_6 = np.append(my_y_np_6,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(7).astype(np.uint8)):   \n",
    "            my_y_np_7 = np.append(my_y_np_7,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_7 = np.append(my_y_np_7,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(8).astype(np.uint8)):  \n",
    "            my_y_np_8 = np.append(my_y_np_8,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_8 = np.append(my_y_np_8,np.array(1).astype(np.uint8))\n",
    "            \n",
    "        if (np.array(ext[1:]).astype(np.uint8) == np.array(9).astype(np.uint8)):  \n",
    "            my_y_np_9 = np.append(my_y_np_9,np.array(0).astype(np.uint8))\n",
    "        else: \n",
    "            my_y_np_9 = np.append(my_y_np_9,np.array(1).astype(np.uint8))\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    for filename in filenames_adversarial:\n",
    "        my_x.append(cv2.imread(os.path.join(path_adversarial, filename), 0))\n",
    "        my_y_np_0= np.append(my_y_np_0, np.array(1).astype(np.uint8))\n",
    "        my_y_np_1= np.append(my_y_np_1, np.array(1).astype(np.uint8))\n",
    "        my_y_np_2= np.append(my_y_np_2, np.array(1).astype(np.uint8))\n",
    "        my_y_np_3= np.append(my_y_np_3, np.array(1).astype(np.uint8))\n",
    "        my_y_np_4= np.append(my_y_np_4, np.array(1).astype(np.uint8))\n",
    "        my_y_np_5= np.append(my_y_np_5, np.array(1).astype(np.uint8))\n",
    "        my_y_np_6= np.append(my_y_np_6, np.array(1).astype(np.uint8))\n",
    "        my_y_np_7= np.append(my_y_np_7, np.array(1).astype(np.uint8))\n",
    "        my_y_np_8= np.append(my_y_np_8, np.array(1).astype(np.uint8))\n",
    "        my_y_np_9= np.append(my_y_np_9, np.array(1).astype(np.uint8))\n",
    "    \n",
    "    \n",
    "    my_y_0 = torch.Tensor(torch.from_numpy(my_y_np_0).float())\n",
    "    my_y_1 = torch.Tensor(torch.from_numpy(my_y_np_1).float())\n",
    "    my_y_2 = torch.Tensor(torch.from_numpy(my_y_np_2).float())\n",
    "    my_y_3 = torch.Tensor(torch.from_numpy(my_y_np_3).float())\n",
    "    my_y_4 = torch.Tensor(torch.from_numpy(my_y_np_4).float())\n",
    "    my_y_5 = torch.Tensor(torch.from_numpy(my_y_np_5).float())\n",
    "    my_y_6 = torch.Tensor(torch.from_numpy(my_y_np_6).float())\n",
    "    my_y_7 = torch.Tensor(torch.from_numpy(my_y_np_7).float())\n",
    "    my_y_8 = torch.Tensor(torch.from_numpy(my_y_np_8).float())\n",
    "    my_y_9 = torch.Tensor(torch.from_numpy(my_y_np_9).float())\n",
    "    \n",
    "    \n",
    "    tensor_x = torch.Tensor(my_x)\n",
    "    tensor_x = tensor_x.unsqueeze(1)\n",
    "\n",
    "    return tensor_x, my_y_0, my_y_1, my_y_2, my_y_3, my_y_4, my_y_5, my_y_6, my_y_7, my_y_8, my_y_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train_benign(path, filenames):\n",
    "    my_x = []\n",
    "    my_y_np = np.array([])\n",
    "    \n",
    "    for filename in filenames:\n",
    "        my_x.append(cv2.imread(os.path.join(path, filename), 0))\n",
    "        pre, ext = os.path.splitext(os.path.join(path, filename))\n",
    "        my_y_np = np.append(my_y_np, np.array(ext[1:]).astype(np.uint8))\n",
    "        \n",
    "    my_y = torch.from_numpy(my_y_np).float()\n",
    "    \n",
    "    tensor_x = torch.Tensor(my_x)\n",
    "    tensor_x = tensor_x.unsqueeze(1)\n",
    "    tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x,tensor_y)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train_both(path_benign, filenames_benign, path_adversarial, filenames_adversarial):\n",
    "    '''A dataset with all training data, benign and adversarial'''\n",
    "    \n",
    "    my_x = []\n",
    "    my_y_np = np.array([])\n",
    "    \n",
    "    for filename in filenames_benign:\n",
    "        my_x.append(cv2.imread(os.path.join(path_benign, filename), 0))\n",
    "        my_y_np= np.append(my_y_np, np.array(0).astype(np.uint8))\n",
    "        \n",
    "    for filename in filenames_adversarial:\n",
    "        my_x.append(cv2.imread(os.path.join(path_adversarial, filename), 0))\n",
    "        my_y_np= np.append(my_y_np, np.array(1).astype(np.uint8))\n",
    "        \n",
    "    my_y = torch.from_numpy(my_y_np).float()\n",
    "    \n",
    "    tensor_x = torch.Tensor(my_x)\n",
    "    tensor_x = tensor_x.unsqueeze(1)\n",
    "    tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x,tensor_y)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test(path, filenames):\n",
    "    my_x = []    \n",
    "    my_y_np = np.array([])\n",
    "    \n",
    "    \n",
    "    for filename in filenames:\n",
    "        \n",
    "        my_x.append(cv2.imread(os.path.join(path, filename), 0))\n",
    "        my_y_np= np.append(my_y_np, np.array(-1).astype(np.uint8))\n",
    "        \n",
    "    my_y = torch.from_numpy(my_y_np).float()\n",
    "    \n",
    "    tensor_x = torch.Tensor(my_x)\n",
    "    tensor_x = tensor_x.unsqueeze(1)\n",
    "    tensor_y = torch.Tensor(my_y)\n",
    "    \n",
    "    dataset = TensorDataset(tensor_x,tensor_y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(digit, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping):\n",
    "    '''Can be used to train both a digit specific network and digit classifier'''\n",
    "    \n",
    "    all_train_losses = []\n",
    "    all_valid_losses = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_n = 0\n",
    "        \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_n = 0\n",
    "        \n",
    "        network.train()\n",
    "        for i, (X,y) in enumerate(dataloader_train):\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            output = network(X)\n",
    "            loss = criterion(output, y.long())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss += loss.item() * y.size(0)\n",
    "            train_acc += (output.max(1)[1] == y).sum().item()\n",
    "            train_n += y.size(0)\n",
    "        \n",
    "        train_loss = train_loss / train_n\n",
    "        all_train_losses.append(train_loss)\n",
    "\n",
    "        network.eval()\n",
    "        for i, (X,y) in enumerate(dataloader_val):\n",
    "            X, y = X.cuda(), y.cuda()        \n",
    "            output = network(X)\n",
    "            loss = criterion(output, y.long())\n",
    "            val_loss += loss.item() * y.size(0)\n",
    "            val_acc += (output.max(1)[1] == y).sum().item()\n",
    "            val_n += y.size(0)\n",
    "            \n",
    "        val_loss = val_loss/val_n\n",
    "        all_valid_losses.append(val_loss)\n",
    "\n",
    "        early_stopping(val_loss, network)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print('epoch:{}, \\t lr:{}, \\n train loss:{}, \\t val loss:{}, \\n train acc:{}, \\t\\t\\t val acc:{} \\n\\n'.format(epoch, scheduler.get_last_lr() , train_loss, val_loss, train_acc/train_n, val_acc/val_n))\n",
    "    \n",
    "        \n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    network.load_state_dict(torch.load('checkpoint_{}.pt'.format(digit)))\n",
    "\n",
    "    return  network, all_train_losses, all_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full(network_benign, network_0, network_1, network_2, network_3, network_4, network_5, network_6, network_7, network_8, network_9, dataloader):\n",
    "    '''Predicts the digit on the images and bades on the prediction forwards the input to a digit specific 0-1 classifier'''\n",
    "    \n",
    "    network_benign.eval()\n",
    "    network_0.eval()\n",
    "    network_1.eval()\n",
    "    network_2.eval()\n",
    "    network_3.eval()\n",
    "    network_4.eval()\n",
    "    network_5.eval()\n",
    "    network_6.eval()\n",
    "    network_7.eval()\n",
    "    network_8.eval()\n",
    "    network_9.eval()\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for i, (X,y) in enumerate(dataloader):\n",
    "        X = X.cuda()\n",
    "        output = network_benign(X)\n",
    "        pred_initial = output.max(1)[1].item()\n",
    "        if pred_initial == 0: output_binary = network_0(X)\n",
    "        if pred_initial == 1: output_binary = network_1(X)\n",
    "        if pred_initial == 2: output_binary = network_2(X)\n",
    "        if pred_initial == 3: output_binary = network_3(X)\n",
    "        if pred_initial == 4: output_binary = network_4(X)\n",
    "        if pred_initial == 5: output_binary = network_5(X)\n",
    "        if pred_initial == 6: output_binary = network_6(X)\n",
    "        if pred_initial == 7: output_binary = network_7(X)\n",
    "        if pred_initial == 8: output_binary = network_8(X)\n",
    "        if pred_initial == 9: output_binary = network_9(X)\n",
    "            \n",
    "        preds.append(output_binary.max(1)[1].item())\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_benign = os.path.join(os.getcwd(), \"ch01-train\")\n",
    "filenames_train_benign = os.listdir(path_train_benign)\n",
    "\n",
    "path_train_adversarial = os.path.join(os.getcwd(), \"ch02-train\")\n",
    "filenames_train_adversarial = os.listdir(path_train_adversarial)\n",
    "\n",
    "path_test = os.path.join(os.getcwd(), \"ch02-test\")\n",
    "filenames_test = os.listdir(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x, tensor_y_0, tensor_y_1, tensor_y_2, tensor_y_3, tensor_y_4, tensor_y_5, tensor_y_6, tensor_y_7, tensor_y_8 , tensor_y_9 = data_train(path_train_benign, filenames_train_benign, path_train_adversarial, filenames_train_adversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_0 = TensorDataset(tensor_x,tensor_y_0)\n",
    "torch.save(dataset_train_0, 'dataset_train_0.pt')\n",
    "\n",
    "dataset_train_1 = TensorDataset(tensor_x,tensor_y_1)\n",
    "torch.save(dataset_train_1, 'dataset_train_1.pt')\n",
    "\n",
    "dataset_train_2 = TensorDataset(tensor_x,tensor_y_2)\n",
    "torch.save(dataset_train_2, 'dataset_train_2.pt')\n",
    "\n",
    "dataset_train_3 = TensorDataset(tensor_x,tensor_y_3)\n",
    "torch.save(dataset_train_3, 'dataset_train_3.pt')\n",
    "\n",
    "dataset_train_4 = TensorDataset(tensor_x,tensor_y_4)\n",
    "torch.save(dataset_train_4, 'dataset_train_4.pt')\n",
    "\n",
    "dataset_train_5 = TensorDataset(tensor_x,tensor_y_5)\n",
    "torch.save(dataset_train_5, 'dataset_train_5.pt')\n",
    "\n",
    "dataset_train_6 = TensorDataset(tensor_x,tensor_y_6)\n",
    "torch.save(dataset_train_6, 'dataset_train_6.pt')\n",
    "\n",
    "dataset_train_7 = TensorDataset(tensor_x,tensor_y_7)\n",
    "torch.save(dataset_train_7, 'dataset_train_7.pt')\n",
    "\n",
    "dataset_train_8 = TensorDataset(tensor_x,tensor_y_8)\n",
    "torch.save(dataset_train_8, 'dataset_train_8.pt')\n",
    "\n",
    "dataset_train_9 = TensorDataset(tensor_x,tensor_y_9)\n",
    "torch.save(dataset_train_9, 'dataset_train_9.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save all digit-specific network that predict 0 or 1 (0-1 networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.005411).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.038484688440337776, \t val loss:0.005410688187042251, \n",
      " train acc:0.9897, \t\t\t val acc:0.9983 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005411 --> 0.002965).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.007511958993715234, \t val loss:0.0029648342644097284, \n",
      " train acc:0.9975875, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002965 --> 0.001949).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.0061023245645876155, \t val loss:0.001948927617701702, \n",
      " train acc:0.9981, \t\t\t val acc:0.99935 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001949 --> 0.001492).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.005075410206442757, \t val loss:0.001491746102896286, \n",
      " train acc:0.9984, \t\t\t val acc:0.999575 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.0038264741954735656, \t val loss:0.0018987348408612888, \n",
      " train acc:0.9988125, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001492 --> 0.001153).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.0025110761899108185, \t val loss:0.001152691369742388, \n",
      " train acc:0.9992875, \t\t\t val acc:0.999575 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001153 --> 0.001061).  Saving model ...\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.002533814136491128, \t val loss:0.0010612675006763312, \n",
      " train acc:0.99915, \t\t\t val acc:0.999625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.0021438708943860548, \t val loss:0.0012459435142380243, \n",
      " train acc:0.999225, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.001869596263286894, \t val loss:0.001107520089839818, \n",
      " train acc:0.9993875, \t\t\t val acc:0.999625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0021216554541670122, \t val loss:0.0012596037386305397, \n",
      " train acc:0.999325, \t\t\t val acc:0.999625 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001061 --> 0.000911).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0016487933331058116, \t val loss:0.0009106595568281591, \n",
      " train acc:0.9993875, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.000911 --> 0.000834).  Saving model ...\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.00149112323145564, \t val loss:0.0008343009248143062, \n",
      " train acc:0.999475, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.000834 --> 0.000742).  Saving model ...\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0010709644377323911, \t val loss:0.0007420816499875059, \n",
      " train acc:0.99965, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.001035680762793595, \t val loss:0.0010293482157933056, \n",
      " train acc:0.99965, \t\t\t val acc:0.9997 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001270073464272241, \t val loss:0.0009087336120416012, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9997 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0007419544846452368, \t val loss:0.0008258484396994391, \n",
      " train acc:0.999725, \t\t\t val acc:0.999675 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.000874282016087426, \t val loss:0.0010508934833135754, \n",
      " train acc:0.9996875, \t\t\t val acc:0.999625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0007530719849740705, \t val loss:0.0008864293209975813, \n",
      " train acc:0.9996875, \t\t\t val acc:0.9997 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0009759890096157846, \t val loss:0.0007613791075728386, \n",
      " train acc:0.9996625, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.00038250611922341306, \t val loss:0.0008372824528207989, \n",
      " train acc:0.9998375, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.000742 --> 0.000697).  Saving model ...\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0006544162922908917, \t val loss:0.0006974774589357651, \n",
      " train acc:0.999775, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0005198133058834624, \t val loss:0.0007719845739613447, \n",
      " train acc:0.999825, \t\t\t val acc:0.999775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.00046629326921794243, \t val loss:0.0008157394434792508, \n",
      " train acc:0.9998125, \t\t\t val acc:0.9997 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0005192231156250428, \t val loss:0.0008481931464755039, \n",
      " train acc:0.99985, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0003492575690761986, \t val loss:0.000895356915210188, \n",
      " train acc:0.9998875, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0004071304021820936, \t val loss:0.0008393244107537908, \n",
      " train acc:0.999875, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0003166599448856281, \t val loss:0.0007820019838598195, \n",
      " train acc:0.9999, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.00017522550183398283, \t val loss:0.0009452007571787084, \n",
      " train acc:0.9999625, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.000610207635470966, \t val loss:0.0008250925095443883, \n",
      " train acc:0.999825, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0006302396328219395, \t val loss:0.0007613286694815258, \n",
      " train acc:0.999775, \t\t\t val acc:0.9997 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0003748672298094398, \t val loss:0.0007210643034737934, \n",
      " train acc:0.9998375, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:31, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0003521255570482202, \t val loss:0.0007095633569234615, \n",
      " train acc:0.9998625, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:32, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0003157865389278273, \t val loss:0.0008041951859264989, \n",
      " train acc:0.9998625, \t\t\t val acc:0.999725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.000697 --> 0.000683).  Saving model ...\n",
      "epoch:33, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.00026884617702667006, \t val loss:0.0006833938996996826, \n",
      " train acc:0.9999, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.000683 --> 0.000681).  Saving model ...\n",
      "epoch:34, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00013879316890904033, \t val loss:0.0006807145430754687, \n",
      " train acc:0.999975, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:35, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0005729458143389082, \t val loss:0.0007347841140685926, \n",
      " train acc:0.9998375, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:36, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00039584098123457423, \t val loss:0.0007764990222556342, \n",
      " train acc:0.9998625, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:37, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00022340638231809783, \t val loss:0.0007520681147621069, \n",
      " train acc:0.999925, \t\t\t val acc:0.999775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:38, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0003399387370457265, \t val loss:0.0007625468788028542, \n",
      " train acc:0.999875, \t\t\t val acc:0.999775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:39, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.00011780464364352525, \t val loss:0.0007506500024668254, \n",
      " train acc:0.9999625, \t\t\t val acc:0.999775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:40, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.00036183492790007444, \t val loss:0.0007624614766787927, \n",
      " train acc:0.9999, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:41, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.00026087635649672185, \t val loss:0.0007414055988322408, \n",
      " train acc:0.9999125, \t\t\t val acc:0.9998 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:42, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0002872774811897332, \t val loss:0.0007250884662737868, \n",
      " train acc:0.9999, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:43, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.00026210895022857155, \t val loss:0.0007484899768339445, \n",
      " train acc:0.9999125, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:44, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.00019249805231474202, \t val loss:0.0007602534956305576, \n",
      " train acc:0.999925, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:45, \t lr:[1.0077695999999996e-05], \n",
      " train loss:9.609486313708881e-05, \t val loss:0.0007715930634153505, \n",
      " train acc:0.999975, \t\t\t val acc:0.99975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:46, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0001774055880234264, \t val loss:0.0007780300348317388, \n",
      " train acc:0.9999375, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:47, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.00030771389633444795, \t val loss:0.0007668383309260538, \n",
      " train acc:0.999925, \t\t\t val acc:0.9998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:48, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0001478698737216555, \t val loss:0.0007695257999171833, \n",
      " train acc:0.9999375, \t\t\t val acc:0.999775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_0.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_0.pt')\n",
    "network, all_train_losses, all_valid_losses = train(0, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.015556).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.027249919626576594, \t val loss:0.015555696023255586, \n",
      " train acc:0.9918875, \t\t\t val acc:0.99655 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.007563754330918891, \t val loss:0.023733082780241967, \n",
      " train acc:0.9978625, \t\t\t val acc:0.9947 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.015556 --> 0.007239).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.005566834649868542, \t val loss:0.007239051377028227, \n",
      " train acc:0.9985, \t\t\t val acc:0.99855 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.007239 --> 0.005782).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.004871092869628319, \t val loss:0.0057818080198019746, \n",
      " train acc:0.9983375, \t\t\t val acc:0.998475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.0041566504538648585, \t val loss:0.0075668090719729665, \n",
      " train acc:0.9986375, \t\t\t val acc:0.99825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005782 --> 0.003283).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.002845604472214109, \t val loss:0.003283098232455086, \n",
      " train acc:0.999, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.0025184869260487176, \t val loss:0.004255867572390707, \n",
      " train acc:0.999125, \t\t\t val acc:0.9987 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.0026775897609353705, \t val loss:0.003436198210073053, \n",
      " train acc:0.9991, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003283 --> 0.002756).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.0021793780127731, \t val loss:0.0027555317649126665, \n",
      " train acc:0.9993, \t\t\t val acc:0.99915 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0023284846074895084, \t val loss:0.0036789627809426747, \n",
      " train acc:0.999225, \t\t\t val acc:0.99895 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002756 --> 0.002457).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0015725372912989088, \t val loss:0.0024572924272419187, \n",
      " train acc:0.999425, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002457 --> 0.002281).  Saving model ...\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0015671734596153784, \t val loss:0.0022805072960577493, \n",
      " train acc:0.9995125, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0011725842716158667, \t val loss:0.002793377046310002, \n",
      " train acc:0.9995625, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.001109697213011944, \t val loss:0.008569316417045308, \n",
      " train acc:0.9995875, \t\t\t val acc:0.9985 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002281 --> 0.002267).  Saving model ...\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0013795089433536192, \t val loss:0.0022672737500703762, \n",
      " train acc:0.9995625, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002267 --> 0.002207).  Saving model ...\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0011107519619094092, \t val loss:0.0022068048389865228, \n",
      " train acc:0.9997, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0007623065191197213, \t val loss:0.002694866213347268, \n",
      " train acc:0.9997, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0007670874097167143, \t val loss:0.0027571673303447256, \n",
      " train acc:0.9997625, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0006902633663018754, \t val loss:0.0028060554856500345, \n",
      " train acc:0.99975, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0007386088309063496, \t val loss:0.0025927095976181307, \n",
      " train acc:0.9998, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0004811376116708434, \t val loss:0.003023290651867512, \n",
      " train acc:0.99985, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.00042332935966867555, \t val loss:0.0025394132847847365, \n",
      " train acc:0.999775, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.00033362965446538244, \t val loss:0.0031445222685890354, \n",
      " train acc:0.9998625, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0005342850563340633, \t val loss:0.0022378259677990455, \n",
      " train acc:0.9998, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0005244035434148955, \t val loss:0.0023715387670412372, \n",
      " train acc:0.9997875, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0005979347235675853, \t val loss:0.002500251881853583, \n",
      " train acc:0.9998, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.00044618133700153175, \t val loss:0.0024842861020797215, \n",
      " train acc:0.9998625, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0003785170955599339, \t val loss:0.0024583520472662023, \n",
      " train acc:0.9999, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0004901141164244079, \t val loss:0.0025905809229925495, \n",
      " train acc:0.99985, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0002789964210448595, \t val loss:0.0030483793775265013, \n",
      " train acc:0.9998875, \t\t\t val acc:0.999275 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_1.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_1.pt')\n",
    "network, all_train_losses, all_valid_losses = train(1, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.012796).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.050377783285733314, \t val loss:0.01279556173197925, \n",
      " train acc:0.9859375, \t\t\t val acc:0.9962 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.012796 --> 0.006462).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.013309736154135316, \t val loss:0.006462080015987158, \n",
      " train acc:0.9956375, \t\t\t val acc:0.997725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.006462 --> 0.005857).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.009378540619387058, \t val loss:0.005856859980430454, \n",
      " train acc:0.9970375, \t\t\t val acc:0.998025 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005857 --> 0.004194).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.007909845220527496, \t val loss:0.004194480999722146, \n",
      " train acc:0.9974375, \t\t\t val acc:0.998575 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.006677716392063303, \t val loss:0.005778286029392621, \n",
      " train acc:0.9978125, \t\t\t val acc:0.998075 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004194 --> 0.003826).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.004982764032916748, \t val loss:0.003825540131283924, \n",
      " train acc:0.9983875, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003826 --> 0.003728).  Saving model ...\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.004396003784478489, \t val loss:0.00372838080683141, \n",
      " train acc:0.998575, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003728 --> 0.003501).  Saving model ...\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.0044024039701984295, \t val loss:0.0035013981081880047, \n",
      " train acc:0.99835, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.003473269681349484, \t val loss:0.003891872243765101, \n",
      " train acc:0.99875, \t\t\t val acc:0.998725 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0033214965670747914, \t val loss:0.0037227923020545857, \n",
      " train acc:0.9988875, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.002666718791074527, \t val loss:0.0035297315272824563, \n",
      " train acc:0.9991125, \t\t\t val acc:0.9988 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003501 --> 0.003174).  Saving model ...\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0023225657434270035, \t val loss:0.0031743623122780264, \n",
      " train acc:0.9992875, \t\t\t val acc:0.998875 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0021218067172796055, \t val loss:0.0034237325496993434, \n",
      " train acc:0.9992, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0024503257234946433, \t val loss:0.0037028939730208094, \n",
      " train acc:0.9990125, \t\t\t val acc:0.998725 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003174 --> 0.003077).  Saving model ...\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0024709907716725867, \t val loss:0.0030765505364441195, \n",
      " train acc:0.9991, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003077 --> 0.003063).  Saving model ...\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0019342504656153323, \t val loss:0.0030627302902003065, \n",
      " train acc:0.99945, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003063 --> 0.002624).  Saving model ...\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001253739241123094, \t val loss:0.0026242502465737287, \n",
      " train acc:0.999475, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0018679129072373599, \t val loss:0.00284916286353141, \n",
      " train acc:0.999275, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001438257822806645, \t val loss:0.00267181682381804, \n",
      " train acc:0.9995625, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0012019765882141996, \t val loss:0.003365067773910164, \n",
      " train acc:0.9995875, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0010683721421609108, \t val loss:0.0030736013851805637, \n",
      " train acc:0.9996, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0009394512589508054, \t val loss:0.0029535289530964633, \n",
      " train acc:0.9996, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0009175940825989528, \t val loss:0.0032935012254875972, \n",
      " train acc:0.9996875, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.001092298045877743, \t val loss:0.00349104004688906, \n",
      " train acc:0.9995875, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001104671694691001, \t val loss:0.0030654998191629716, \n",
      " train acc:0.9995625, \t\t\t val acc:0.999 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0008828301546494913, \t val loss:0.0032132329652296305, \n",
      " train acc:0.9997, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0009690855157921903, \t val loss:0.0030629772596616135, \n",
      " train acc:0.999675, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0006868918782810397, \t val loss:0.0031398423624414535, \n",
      " train acc:0.99975, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0006672453274714599, \t val loss:0.003275312823765978, \n",
      " train acc:0.9997875, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.000888206535550222, \t val loss:0.003186436674627481, \n",
      " train acc:0.9996625, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0005828083343096182, \t val loss:0.003114095895052222, \n",
      " train acc:0.9997625, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_2.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_2.pt')\n",
    "network, all_train_losses, all_valid_losses = train(2, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.008888).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.0468820444017183, \t val loss:0.008887981683015824, \n",
      " train acc:0.98665, \t\t\t val acc:0.99735 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.008888 --> 0.004980).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.011305375904918764, \t val loss:0.004980088987457566, \n",
      " train acc:0.9962875, \t\t\t val acc:0.99865 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.008446330918831518, \t val loss:0.006334131938123028, \n",
      " train acc:0.997675, \t\t\t val acc:0.99825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004980 --> 0.003689).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.006887601084775087, \t val loss:0.003688836927548982, \n",
      " train acc:0.9978125, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003689 --> 0.003437).  Saving model ...\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.00584572087879169, \t val loss:0.0034365954246546606, \n",
      " train acc:0.9982125, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003437 --> 0.003164).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.003919943568886447, \t val loss:0.003163545937242452, \n",
      " train acc:0.998825, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003164 --> 0.002977).  Saving model ...\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.0038278638138326644, \t val loss:0.002976962540578097, \n",
      " train acc:0.9987375, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002977 --> 0.002852).  Saving model ...\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.0029709905380912458, \t val loss:0.0028519055447563005, \n",
      " train acc:0.999025, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.003164175586948295, \t val loss:0.0035345495295361616, \n",
      " train acc:0.999025, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.003005346213208941, \t val loss:0.003447694869960833, \n",
      " train acc:0.9990375, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002852 --> 0.002799).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0023838739799413814, \t val loss:0.0027987102853796386, \n",
      " train acc:0.9991875, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0019392345202674732, \t val loss:0.0030236296209064676, \n",
      " train acc:0.9992875, \t\t\t val acc:0.999 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002799 --> 0.002757).  Saving model ...\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0020826950649230186, \t val loss:0.002756747830539825, \n",
      " train acc:0.9992, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.001381184561000282, \t val loss:0.0028148664603277213, \n",
      " train acc:0.999575, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0016817562257461873, \t val loss:0.0029981154650966344, \n",
      " train acc:0.9993875, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0013738726377209105, \t val loss:0.0029883895996757927, \n",
      " train acc:0.9995375, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002757 --> 0.002747).  Saving model ...\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0014493226261458859, \t val loss:0.0027468926237050255, \n",
      " train acc:0.9995125, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0013611709450802323, \t val loss:0.003228722891650614, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0008339382618534955, \t val loss:0.003539930774540987, \n",
      " train acc:0.9997625, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0009373631960947797, \t val loss:0.003468014704561108, \n",
      " train acc:0.9997375, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0012822273945078337, \t val loss:0.003358766998349074, \n",
      " train acc:0.9995125, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0008437714377761836, \t val loss:0.0032925103814616763, \n",
      " train acc:0.9996875, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0007087565968252129, \t val loss:0.0032545338417530275, \n",
      " train acc:0.9997125, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0007874846288179015, \t val loss:0.00334450503510825, \n",
      " train acc:0.99975, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.000859632113612787, \t val loss:0.0033372657994243356, \n",
      " train acc:0.9997125, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.000686561736902965, \t val loss:0.003266682000030198, \n",
      " train acc:0.9998, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0007440757957485545, \t val loss:0.0031764859181691064, \n",
      " train acc:0.9997875, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.000885513058750621, \t val loss:0.003129132286627521, \n",
      " train acc:0.9997125, \t\t\t val acc:0.99935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0004650785003279111, \t val loss:0.0031817045886128083, \n",
      " train acc:0.999875, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0008382038701109977, \t val loss:0.0030968432050454795, \n",
      " train acc:0.9997375, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0005996731664922436, \t val loss:0.0030157555719310153, \n",
      " train acc:0.999775, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_3.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_3.pt')\n",
    "network, all_train_losses, all_valid_losses = train(3, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.007325).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.043063536810688675, \t val loss:0.007324830305017531, \n",
      " train acc:0.9884375, \t\t\t val acc:0.997375 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.007325 --> 0.005431).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.011310960925999097, \t val loss:0.005430806345044403, \n",
      " train acc:0.996475, \t\t\t val acc:0.998125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.00884400648662413, \t val loss:0.008898414231821515, \n",
      " train acc:0.997125, \t\t\t val acc:0.997275 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.008755193696392235, \t val loss:0.00651723427119141, \n",
      " train acc:0.9974, \t\t\t val acc:0.9978 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005431 --> 0.004516).  Saving model ...\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.007488618944566406, \t val loss:0.004515690790070221, \n",
      " train acc:0.9978875, \t\t\t val acc:0.998575 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004516 --> 0.003873).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.005611289911299536, \t val loss:0.0038733002367938754, \n",
      " train acc:0.9982, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003873 --> 0.003474).  Saving model ...\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.0048060961010363825, \t val loss:0.0034739147014392073, \n",
      " train acc:0.998475, \t\t\t val acc:0.998875 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.004262701442402613, \t val loss:0.004427690447718487, \n",
      " train acc:0.9986125, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.00476156755026459, \t val loss:0.004221560269875044, \n",
      " train acc:0.9983125, \t\t\t val acc:0.998675 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003474 --> 0.003360).  Saving model ...\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.003953689353449591, \t val loss:0.0033598263694253547, \n",
      " train acc:0.9986625, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0034427238361698985, \t val loss:0.0038733857023522432, \n",
      " train acc:0.9988875, \t\t\t val acc:0.99885 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0026902364263893105, \t val loss:0.0041184795451416, \n",
      " train acc:0.9992375, \t\t\t val acc:0.9988 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.002782228331933402, \t val loss:0.003831946480235001, \n",
      " train acc:0.99895, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003360 --> 0.003225).  Saving model ...\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0030329372035397682, \t val loss:0.003225096110926825, \n",
      " train acc:0.999025, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0024344296393355763, \t val loss:0.003275626724053109, \n",
      " train acc:0.9992375, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0018926205592870247, \t val loss:0.003280957237218354, \n",
      " train acc:0.999375, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003225 --> 0.002985).  Saving model ...\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001809505495376834, \t val loss:0.002984725923431324, \n",
      " train acc:0.9993625, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0021450047939133585, \t val loss:0.003678450773052464, \n",
      " train acc:0.9991875, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0018325924208826563, \t val loss:0.0033762289833637626, \n",
      " train acc:0.9993625, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0018296856592301084, \t val loss:0.0036879681466336477, \n",
      " train acc:0.9993625, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0013591051626980516, \t val loss:0.0034881590719267478, \n",
      " train acc:0.9995375, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0013884345867508727, \t val loss:0.0034156500958323704, \n",
      " train acc:0.999475, \t\t\t val acc:0.999 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002985 --> 0.002969).  Saving model ...\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0013773327985203195, \t val loss:0.002968519021019165, \n",
      " train acc:0.9996125, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0012182977026448953, \t val loss:0.0030373652598587797, \n",
      " train acc:0.999575, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0013939303851186423, \t val loss:0.003286615115008044, \n",
      " train acc:0.99945, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0009607951026261617, \t val loss:0.003242778319876561, \n",
      " train acc:0.9996125, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0012128791179791278, \t val loss:0.0033693021977800526, \n",
      " train acc:0.9996375, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0009437938339973698, \t val loss:0.003365080243749071, \n",
      " train acc:0.99965, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001055725835202611, \t val loss:0.003904774114306383, \n",
      " train acc:0.999675, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0011445841267800916, \t val loss:0.0031025829328424153, \n",
      " train acc:0.9995875, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.000833398362900607, \t val loss:0.0034640580034316372, \n",
      " train acc:0.9997375, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:31, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0007224772386662835, \t val loss:0.00344914807756204, \n",
      " train acc:0.9997375, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:32, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0010006608971891184, \t val loss:0.003529488538733858, \n",
      " train acc:0.999625, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:33, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0011018877537340471, \t val loss:0.003032927739158731, \n",
      " train acc:0.9996125, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:34, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0007188629008372004, \t val loss:0.0030667413227477482, \n",
      " train acc:0.999725, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:35, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0007575416723706894, \t val loss:0.0030986229058199114, \n",
      " train acc:0.9997375, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:36, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.000998175583547493, \t val loss:0.0031253379591631527, \n",
      " train acc:0.9996875, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_4.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_4.pt')\n",
    "network, all_train_losses, all_valid_losses = train(4, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.008405).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.04375633077623788, \t val loss:0.008405021484743338, \n",
      " train acc:0.98785, \t\t\t val acc:0.99705 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.008405 --> 0.007331).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.01157479639899684, \t val loss:0.007331065645138733, \n",
      " train acc:0.9962125, \t\t\t val acc:0.99755 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.007331 --> 0.005396).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.008510998942115112, \t val loss:0.005396388988243416, \n",
      " train acc:0.9973875, \t\t\t val acc:0.99825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.0073340061962589975, \t val loss:0.007804317136364989, \n",
      " train acc:0.997775, \t\t\t val acc:0.997625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.006097921441635117, \t val loss:0.0059047447438526435, \n",
      " train acc:0.9981, \t\t\t val acc:0.9982 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005396 --> 0.002998).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.00496789890526452, \t val loss:0.0029982959579079762, \n",
      " train acc:0.9984375, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.003916007607556822, \t val loss:0.0041345832683146, \n",
      " train acc:0.9988125, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.003860455340021872, \t val loss:0.0031319594729575326, \n",
      " train acc:0.998775, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.004112277923553484, \t val loss:0.003676719847082859, \n",
      " train acc:0.998725, \t\t\t val acc:0.999 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.003950681805508429, \t val loss:0.003155195823514077, \n",
      " train acc:0.9987375, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002998 --> 0.002916).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.002562686201899851, \t val loss:0.0029161402875404747, \n",
      " train acc:0.999075, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0024269481596336847, \t val loss:0.003274790212400512, \n",
      " train acc:0.9991, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002916 --> 0.002676).  Saving model ...\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.002040492099483754, \t val loss:0.0026762634695807717, \n",
      " train acc:0.9993, \t\t\t val acc:0.999275 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.002280153504699956, \t val loss:0.00309623635509015, \n",
      " train acc:0.999225, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0017509089914769446, \t val loss:0.002873741547991142, \n",
      " train acc:0.999325, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002676 --> 0.002657).  Saving model ...\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001809787563469945, \t val loss:0.002657477583083164, \n",
      " train acc:0.9993125, \t\t\t val acc:0.999275 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001320446338637612, \t val loss:0.0036246084079180037, \n",
      " train acc:0.9995375, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0014624588822852048, \t val loss:0.0027718145125934825, \n",
      " train acc:0.9995125, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0013998711427182116, \t val loss:0.002773508580394264, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002657 --> 0.002388).  Saving model ...\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0011027455379535695, \t val loss:0.002387654356385883, \n",
      " train acc:0.9996375, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0012388643515627337, \t val loss:0.0024291686746801644, \n",
      " train acc:0.9995875, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0010154179538847644, \t val loss:0.0024233087984047415, \n",
      " train acc:0.9996625, \t\t\t val acc:0.99935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0009656555270145873, \t val loss:0.0031894405296609305, \n",
      " train acc:0.999675, \t\t\t val acc:0.999325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0008831746786431267, \t val loss:0.0027716448835129882, \n",
      " train acc:0.99965, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0011236910540828944, \t val loss:0.002638147185633727, \n",
      " train acc:0.9996125, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0008580432126709411, \t val loss:0.0025888021469758086, \n",
      " train acc:0.9996875, \t\t\t val acc:0.99935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0006900817399188298, \t val loss:0.0027661263817033727, \n",
      " train acc:0.999725, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0007253356135152387, \t val loss:0.002742888521446116, \n",
      " train acc:0.9997125, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0009324831442909186, \t val loss:0.0025756743764323345, \n",
      " train acc:0.99965, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0008146944211127845, \t val loss:0.002686669135739135, \n",
      " train acc:0.999675, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0008337605874192121, \t val loss:0.0024123859709944784, \n",
      " train acc:0.99975, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:31, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0007240868045659539, \t val loss:0.002629510205317024, \n",
      " train acc:0.9997, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:32, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0006489932196106764, \t val loss:0.0025296381465193464, \n",
      " train acc:0.9998125, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:33, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.000906257865915449, \t val loss:0.0025812669212892728, \n",
      " train acc:0.9996375, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002388 --> 0.002385).  Saving model ...\n",
      "epoch:34, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0006546481395800925, \t val loss:0.002385492959891627, \n",
      " train acc:0.99975, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002385 --> 0.002347).  Saving model ...\n",
      "epoch:35, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0005732197598178345, \t val loss:0.0023474458282361807, \n",
      " train acc:0.9998125, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:36, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00048267750043278, \t val loss:0.002408018989580614, \n",
      " train acc:0.999875, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:37, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0005133188032617071, \t val loss:0.002476045369187787, \n",
      " train acc:0.9998125, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:38, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0005702717854535734, \t val loss:0.002415685869165145, \n",
      " train acc:0.9998, \t\t\t val acc:0.9995 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:39, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.000586506850895352, \t val loss:0.0026187768057022707, \n",
      " train acc:0.9997875, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:40, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0005465468174342049, \t val loss:0.00252999890152762, \n",
      " train acc:0.9998125, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:41, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0006846343447897397, \t val loss:0.002519400779848064, \n",
      " train acc:0.9997375, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0005465359214989234, \t val loss:0.0024886937478885017, \n",
      " train acc:0.999825, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:43, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.000455199212915322, \t val loss:0.002587595512030009, \n",
      " train acc:0.99985, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:44, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0005129168730164637, \t val loss:0.0026498165707401883, \n",
      " train acc:0.999825, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:45, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.00037527261555854425, \t val loss:0.002638647284318455, \n",
      " train acc:0.99985, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:46, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0005223458977717073, \t val loss:0.0025342400248457805, \n",
      " train acc:0.9998125, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:47, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0004667957387807242, \t val loss:0.0025551414593364113, \n",
      " train acc:0.9998125, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:48, \t lr:[1.0077695999999996e-05], \n",
      " train loss:0.0006554174080575706, \t val loss:0.0025266916971969735, \n",
      " train acc:0.9997875, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:49, \t lr:[6.046617599999998e-06], \n",
      " train loss:0.0007261977586432422, \t val loss:0.0025512021107834213, \n",
      " train acc:0.9997625, \t\t\t val acc:0.99945 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_5.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_5.pt')\n",
    "network, all_train_losses, all_valid_losses = train(5, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.004860).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.03284938612431288, \t val loss:0.0048595300398344985, \n",
      " train acc:0.990975, \t\t\t val acc:0.998375 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004860 --> 0.003470).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.0073693085777194935, \t val loss:0.0034699708041734992, \n",
      " train acc:0.9976625, \t\t\t val acc:0.9989 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003470 --> 0.002656).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.0055697822486239605, \t val loss:0.0026558905305166264, \n",
      " train acc:0.998025, \t\t\t val acc:0.99895 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002656 --> 0.002422).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.004831439958930423, \t val loss:0.0024216098023898667, \n",
      " train acc:0.998375, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.003828373222260052, \t val loss:0.0038123544656831656, \n",
      " train acc:0.998825, \t\t\t val acc:0.998525 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002422 --> 0.002402).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.0027508597743846623, \t val loss:0.0024019158004804923, \n",
      " train acc:0.9991375, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.0025839386209036094, \t val loss:0.0028726529508567183, \n",
      " train acc:0.9991375, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.002510546921262767, \t val loss:0.0033411113880174527, \n",
      " train acc:0.999125, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002402 --> 0.002061).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.002344119786941201, \t val loss:0.002061068633406103, \n",
      " train acc:0.9991875, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0025498923142952437, \t val loss:0.0021680855353435617, \n",
      " train acc:0.9991125, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.002061 --> 0.001953).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0014276278406562823, \t val loss:0.0019527917649021218, \n",
      " train acc:0.99955, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001953 --> 0.001905).  Saving model ...\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0018735761326550346, \t val loss:0.0019047811288332014, \n",
      " train acc:0.9993, \t\t\t val acc:0.999275 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.001209777757399661, \t val loss:0.002382058921107955, \n",
      " train acc:0.9995625, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0012307519063207764, \t val loss:0.002715808767641397, \n",
      " train acc:0.9995625, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.001905 --> 0.001822).  Saving model ...\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0017006292427926212, \t val loss:0.00182154460346992, \n",
      " train acc:0.9994, \t\t\t val acc:0.9993 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0010923819148611301, \t val loss:0.002249588309246974, \n",
      " train acc:0.999575, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0007492601639040771, \t val loss:0.002068114625022167, \n",
      " train acc:0.9996875, \t\t\t val acc:0.99935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0009673734952744631, \t val loss:0.0027094880748179265, \n",
      " train acc:0.9996875, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0008943279291913484, \t val loss:0.002467858936643506, \n",
      " train acc:0.9996875, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0004447924101193053, \t val loss:0.0037714363684128783, \n",
      " train acc:0.99985, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0006923856544593086, \t val loss:0.0022509213389521558, \n",
      " train acc:0.99975, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0005080231609073346, \t val loss:0.002224850270558841, \n",
      " train acc:0.9998375, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.000602052311373551, \t val loss:0.0022804473580024295, \n",
      " train acc:0.999825, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0004892733526452441, \t val loss:0.0023186667987883927, \n",
      " train acc:0.9998625, \t\t\t val acc:0.999475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0007158051497309969, \t val loss:0.002302564375789495, \n",
      " train acc:0.9997, \t\t\t val acc:0.999375 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0005858914859649432, \t val loss:0.002305003797870186, \n",
      " train acc:0.9997875, \t\t\t val acc:0.9994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0004021263503239183, \t val loss:0.002401525636625572, \n",
      " train acc:0.9997875, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.00048051765088780255, \t val loss:0.00229273160166599, \n",
      " train acc:0.9998375, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.00044460963153556587, \t val loss:0.002384252859227703, \n",
      " train acc:0.9998375, \t\t\t val acc:0.999425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_6.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_6.pt')\n",
    "network, all_train_losses, all_valid_losses = train(6, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.009418).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.03928372174233664, \t val loss:0.009418027699738742, \n",
      " train acc:0.9895625, \t\t\t val acc:0.99765 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.009418 --> 0.006897).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.011227195402653888, \t val loss:0.0068970690093468874, \n",
      " train acc:0.996125, \t\t\t val acc:0.997925 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.006897 --> 0.006872).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.008481007446549484, \t val loss:0.006872415605757851, \n",
      " train acc:0.9971625, \t\t\t val acc:0.997575 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.0074386913646449105, \t val loss:0.007720000498695299, \n",
      " train acc:0.997525, \t\t\t val acc:0.997375 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.006872 --> 0.004780).  Saving model ...\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.005928924384468701, \t val loss:0.0047800853963941336, \n",
      " train acc:0.9980125, \t\t\t val acc:0.998525 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.004456166064363424, \t val loss:0.005070590036734939, \n",
      " train acc:0.9986, \t\t\t val acc:0.998525 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.004165148155605129, \t val loss:0.004824592055432731, \n",
      " train acc:0.99865, \t\t\t val acc:0.998425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.004267741587628552, \t val loss:0.005313086609286256, \n",
      " train acc:0.998675, \t\t\t val acc:0.998225 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004780 --> 0.004258).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.004139955934302998, \t val loss:0.004257941539783496, \n",
      " train acc:0.99855, \t\t\t val acc:0.9987 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.003680707411071671, \t val loss:0.0043804102943220645, \n",
      " train acc:0.998725, \t\t\t val acc:0.998575 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0026773014989821147, \t val loss:0.005077320403834528, \n",
      " train acc:0.99915, \t\t\t val acc:0.99865 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0028178104635105342, \t val loss:0.004984677261718162, \n",
      " train acc:0.9991625, \t\t\t val acc:0.998875 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0023313530794291863, \t val loss:0.005484858768608819, \n",
      " train acc:0.9991375, \t\t\t val acc:0.998875 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0021189427786274793, \t val loss:0.004531484046273181, \n",
      " train acc:0.99925, \t\t\t val acc:0.9989 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.002305401590996576, \t val loss:0.005609034971218171, \n",
      " train acc:0.99925, \t\t\t val acc:0.998675 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0019750544078017355, \t val loss:0.005413993182097784, \n",
      " train acc:0.9993125, \t\t\t val acc:0.999 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.001968713935105734, \t val loss:0.005418331152906557, \n",
      " train acc:0.9992625, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0013667956612605807, \t val loss:0.005190254354618599, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9988 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0016642857212251186, \t val loss:0.005447703139990631, \n",
      " train acc:0.9995, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.001268421973392833, \t val loss:0.0063053319522537316, \n",
      " train acc:0.9995875, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0013273510851350083, \t val loss:0.00533462683964637, \n",
      " train acc:0.9995375, \t\t\t val acc:0.998875 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0010932146787381186, \t val loss:0.00599312372064246, \n",
      " train acc:0.9994875, \t\t\t val acc:0.9989 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.001051016951712836, \t val loss:0.005369992751016241, \n",
      " train acc:0.9995375, \t\t\t val acc:0.999025 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_7.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_7.pt')\n",
    "network, all_train_losses, all_valid_losses = train(7, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_7.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.011893).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.05693370323013514, \t val loss:0.011893319134414196, \n",
      " train acc:0.98265, \t\t\t val acc:0.9964 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.011893 --> 0.007109).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.01659989817198366, \t val loss:0.007109111057315022, \n",
      " train acc:0.9945375, \t\t\t val acc:0.99785 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.011788208941719495, \t val loss:0.009404169050790369, \n",
      " train acc:0.9959875, \t\t\t val acc:0.99665 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.007109 --> 0.005570).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.009758697147559723, \t val loss:0.00556969105170574, \n",
      " train acc:0.9967125, \t\t\t val acc:0.99825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.008465935823196196, \t val loss:0.00568717817151919, \n",
      " train acc:0.99705, \t\t\t val acc:0.99815 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005570 --> 0.005111).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.006076816715474706, \t val loss:0.005110650911158882, \n",
      " train acc:0.99795, \t\t\t val acc:0.998325 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005111 --> 0.004602).  Saving model ...\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.005345207927640877, \t val loss:0.004601865914888913, \n",
      " train acc:0.9981, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.0046599602199406944, \t val loss:0.004674217076727655, \n",
      " train acc:0.99845, \t\t\t val acc:0.99875 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004602 --> 0.004293).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.005157446093816543, \t val loss:0.004292728592333151, \n",
      " train acc:0.998225, \t\t\t val acc:0.99865 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004293 --> 0.004190).  Saving model ...\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.004260494380557066, \t val loss:0.00419003384502139, \n",
      " train acc:0.998575, \t\t\t val acc:0.998625 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.004190 --> 0.003769).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.003350277618891414, \t val loss:0.003768680157257768, \n",
      " train acc:0.9987625, \t\t\t val acc:0.998925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0030087009494149243, \t val loss:0.004023911254925406, \n",
      " train acc:0.9989, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003769 --> 0.003726).  Saving model ...\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0030095924993194787, \t val loss:0.003725969891761997, \n",
      " train acc:0.99895, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003726 --> 0.003637).  Saving model ...\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0026061462654772185, \t val loss:0.0036366692614014026, \n",
      " train acc:0.999, \t\t\t val acc:0.99895 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0028750642657138087, \t val loss:0.003907783817562449, \n",
      " train acc:0.9989875, \t\t\t val acc:0.998775 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003637 --> 0.003538).  Saving model ...\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0023341349225091106, \t val loss:0.0035382191563025117, \n",
      " train acc:0.9991625, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0018413365762310605, \t val loss:0.003966186959507467, \n",
      " train acc:0.9994, \t\t\t val acc:0.998825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003538 --> 0.003353).  Saving model ...\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0021461147536520004, \t val loss:0.003353149502152883, \n",
      " train acc:0.9992875, \t\t\t val acc:0.99895 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0015877095282050958, \t val loss:0.004285335375243346, \n",
      " train acc:0.9994, \t\t\t val acc:0.9989 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0018502446118445733, \t val loss:0.0033975257726371636, \n",
      " train acc:0.9992625, \t\t\t val acc:0.998975 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0013783297821086306, \t val loss:0.003716654894381463, \n",
      " train acc:0.9995875, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.001444460166482861, \t val loss:0.00351679781595667, \n",
      " train acc:0.99955, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0016972971917681547, \t val loss:0.003503530785762632, \n",
      " train acc:0.999325, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0012823933139054589, \t val loss:0.0034329585859696637, \n",
      " train acc:0.99965, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003353 --> 0.003348).  Saving model ...\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001237542440856896, \t val loss:0.003347752222617737, \n",
      " train acc:0.999575, \t\t\t val acc:0.99915 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001105915731104642, \t val loss:0.003482533442000886, \n",
      " train acc:0.999575, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.00100392247059159, \t val loss:0.0034254712756989648, \n",
      " train acc:0.99965, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001286969421932099, \t val loss:0.0034203248309098173, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.003348 --> 0.003334).  Saving model ...\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0010787550410934954, \t val loss:0.0033340471912717477, \n",
      " train acc:0.9995875, \t\t\t val acc:0.99915 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0010571064678183688, \t val loss:0.0034580497223466408, \n",
      " train acc:0.9996625, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0012738044404811489, \t val loss:0.0034301877166866687, \n",
      " train acc:0.9995375, \t\t\t val acc:0.99915 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:31, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0011304441114141923, \t val loss:0.003529629400664544, \n",
      " train acc:0.9995375, \t\t\t val acc:0.9991 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:32, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.000889568498339986, \t val loss:0.0036258396833389723, \n",
      " train acc:0.9996875, \t\t\t val acc:0.999125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:33, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0009468309152584538, \t val loss:0.0036122105576804984, \n",
      " train acc:0.9996625, \t\t\t val acc:0.99905 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:34, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00098712037643553, \t val loss:0.0034328532990005444, \n",
      " train acc:0.9997, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:35, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0009634601655559208, \t val loss:0.0035382776293093683, \n",
      " train acc:0.9997125, \t\t\t val acc:0.999075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:36, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0008805240832624122, \t val loss:0.0034860962786302254, \n",
      " train acc:0.999625, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:37, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0008000705845309994, \t val loss:0.003534887942043849, \n",
      " train acc:0.99975, \t\t\t val acc:0.999175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:38, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.0008266279372471615, \t val loss:0.0035722690978114654, \n",
      " train acc:0.999725, \t\t\t val acc:0.999225 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:39, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0011153903975040975, \t val loss:0.003500264891447182, \n",
      " train acc:0.999625, \t\t\t val acc:0.99925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:40, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0007866687359634, \t val loss:0.003586340684455149, \n",
      " train acc:0.9997125, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:41, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0007383339920542312, \t val loss:0.003608153764535416, \n",
      " train acc:0.9997625, \t\t\t val acc:0.999175 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:42, \t lr:[1.6796159999999994e-05], \n",
      " train loss:0.0008215145609550518, \t val loss:0.0037125213872322886, \n",
      " train acc:0.9997, \t\t\t val acc:0.9992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_8.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_8.pt')\n",
    "network, all_train_losses, all_valid_losses = train(8, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.013561).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.054575201535783706, \t val loss:0.013560591727867723, \n",
      " train acc:0.9832, \t\t\t val acc:0.996325 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.013561 --> 0.010142).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.016414816657686605, \t val loss:0.010142247025668622, \n",
      " train acc:0.9946, \t\t\t val acc:0.99715 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.010142 --> 0.008263).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.012835454135062173, \t val loss:0.008262981516681612, \n",
      " train acc:0.9957, \t\t\t val acc:0.997225 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.008263 --> 0.007080).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.010811123968614266, \t val loss:0.007080085969564971, \n",
      " train acc:0.9965375, \t\t\t val acc:0.997825 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.007080 --> 0.006912).  Saving model ...\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.009656598559365376, \t val loss:0.006912374966288917, \n",
      " train acc:0.9969, \t\t\t val acc:0.9976 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.006912 --> 0.006368).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.007297060279553989, \t val loss:0.006368024390004575, \n",
      " train acc:0.9975875, \t\t\t val acc:0.9981 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.006329732829955173, \t val loss:0.007135647087485995, \n",
      " train acc:0.9979, \t\t\t val acc:0.997675 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.006368 --> 0.005315).  Saving model ...\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.005817383180231264, \t val loss:0.005315202669310384, \n",
      " train acc:0.9981125, \t\t\t val acc:0.9983 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005315 --> 0.005201).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.0053052252008943465, \t val loss:0.005200700355344452, \n",
      " train acc:0.9981, \t\t\t val acc:0.9984 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.005058917679364095, \t val loss:0.006528273395472206, \n",
      " train acc:0.9983375, \t\t\t val acc:0.998075 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.004149791546270717, \t val loss:0.006486929631032399, \n",
      " train acc:0.9985625, \t\t\t val acc:0.997925 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0037170012669448626, \t val loss:0.007150562923798861, \n",
      " train acc:0.998775, \t\t\t val acc:0.9978 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0033847954513697913, \t val loss:0.007710112895467318, \n",
      " train acc:0.9989625, \t\t\t val acc:0.9976 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.0031067848415133993, \t val loss:0.0055954059605683145, \n",
      " train acc:0.9988375, \t\t\t val acc:0.998225 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.005201 --> 0.005130).  Saving model ...\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.003221451271594742, \t val loss:0.005129987407731824, \n",
      " train acc:0.99885, \t\t\t val acc:0.99825 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0029781277908114134, \t val loss:0.00536078296857886, \n",
      " train acc:0.99915, \t\t\t val acc:0.998475 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.002543770890027372, \t val loss:0.005727332606090931, \n",
      " train acc:0.99915, \t\t\t val acc:0.998175 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0022569070731666215, \t val loss:0.006611354191826467, \n",
      " train acc:0.9991125, \t\t\t val acc:0.998 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.0026118100118923395, \t val loss:0.006077089307802089, \n",
      " train acc:0.9990875, \t\t\t val acc:0.998125 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0021954915724158126, \t val loss:0.005600971522546751, \n",
      " train acc:0.999225, \t\t\t val acc:0.9983 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0019544219679990876, \t val loss:0.005627553521348091, \n",
      " train acc:0.9993125, \t\t\t val acc:0.9983 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.001746069436344169, \t val loss:0.005931809152846563, \n",
      " train acc:0.9994875, \t\t\t val acc:0.9984 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0018333867474561658, \t val loss:0.005670241632631042, \n",
      " train acc:0.9994125, \t\t\t val acc:0.998425 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.0021212068118385105, \t val loss:0.005213412804659129, \n",
      " train acc:0.99925, \t\t\t val acc:0.9986 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0013221414943116315, \t val loss:0.005965093042707633, \n",
      " train acc:0.9994625, \t\t\t val acc:0.9984 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0012914072944076565, \t val loss:0.005906275807645489, \n",
      " train acc:0.999575, \t\t\t val acc:0.998325 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.001491617614156496, \t val loss:0.005285932961170419, \n",
      " train acc:0.9994375, \t\t\t val acc:0.99865 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0013251081963119673, \t val loss:0.005321833089333449, \n",
      " train acc:0.9996125, \t\t\t val acc:0.99855 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.0014251214748525625, \t val loss:0.005222401116947049, \n",
      " train acc:0.999525, \t\t\t val acc:0.99865 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dataset_train = torch.load('dataset_train_9.pt')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_train, [80000, 40000])\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size = 128) \n",
    "dataloader_val = DataLoader(val_set, batch_size = 128) \n",
    "\n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.train()\n",
    "epochs = 50\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_9.pt')\n",
    "network, all_train_losses, all_valid_losses = train(9, network, epochs, dataloader_train, dataloader_val, opt, scheduler, early_stopping)\n",
    "\n",
    "torch.save(network.state_dict(), 'network_9.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_benign = data_train_benign(path_train_benign, filenames_train_benign)\n",
    "\n",
    "train_set_benign, val_set_benign = torch.utils.data.random_split(dataset_train_benign, [50000, 10000])\n",
    "\n",
    "dataloader_train_benign = DataLoader(train_set_benign, batch_size = 128) \n",
    "dataloader_val_benign = DataLoader(val_set_benign, batch_size = 128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.072562).  Saving model ...\n",
      "epoch:0, \t lr:[0.001], \n",
      " train loss:0.2528501088538766, \t val loss:0.07256186370998621, \n",
      " train acc:0.91878, \t\t\t val acc:0.9784 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.072562 --> 0.055103).  Saving model ...\n",
      "epoch:1, \t lr:[0.001], \n",
      " train loss:0.07354438481986522, \t val loss:0.05510275904433802, \n",
      " train acc:0.97746, \t\t\t val acc:0.9854 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.055103 --> 0.043482).  Saving model ...\n",
      "epoch:2, \t lr:[0.001], \n",
      " train loss:0.05648715904057026, \t val loss:0.04348218642189167, \n",
      " train acc:0.98288, \t\t\t val acc:0.9869 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.043482 --> 0.036156).  Saving model ...\n",
      "epoch:3, \t lr:[0.001], \n",
      " train loss:0.04719378785192967, \t val loss:0.03615560472337529, \n",
      " train acc:0.98518, \t\t\t val acc:0.9886 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.036156 --> 0.035520).  Saving model ...\n",
      "epoch:4, \t lr:[0.0006], \n",
      " train loss:0.042249644126296046, \t val loss:0.03552038010652177, \n",
      " train acc:0.98694, \t\t\t val acc:0.9883 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.035520 --> 0.028324).  Saving model ...\n",
      "epoch:5, \t lr:[0.0006], \n",
      " train loss:0.03076852274313569, \t val loss:0.028323675464326514, \n",
      " train acc:0.99088, \t\t\t val acc:0.9919 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:6, \t lr:[0.0006], \n",
      " train loss:0.026823153383284806, \t val loss:0.03076766279840376, \n",
      " train acc:0.99172, \t\t\t val acc:0.9912 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:7, \t lr:[0.0006], \n",
      " train loss:0.024979209499061107, \t val loss:0.0301271301840432, \n",
      " train acc:0.99224, \t\t\t val acc:0.9914 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.028324 --> 0.028055).  Saving model ...\n",
      "epoch:8, \t lr:[0.0006], \n",
      " train loss:0.023987709406763317, \t val loss:0.028055243238410913, \n",
      " train acc:0.99196, \t\t\t val acc:0.992 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:9, \t lr:[0.00035999999999999997], \n",
      " train loss:0.021755538538992404, \t val loss:0.030122329866257496, \n",
      " train acc:0.9928, \t\t\t val acc:0.991 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.028055 --> 0.026015).  Saving model ...\n",
      "epoch:10, \t lr:[0.00035999999999999997], \n",
      " train loss:0.01885952875223011, \t val loss:0.026014527996699326, \n",
      " train acc:0.99386, \t\t\t val acc:0.9928 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.026015 --> 0.024675).  Saving model ...\n",
      "epoch:11, \t lr:[0.00035999999999999997], \n",
      " train loss:0.01520339705362916, \t val loss:0.02467517553846701, \n",
      " train acc:0.995, \t\t\t val acc:0.993 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.024675 --> 0.023872).  Saving model ...\n",
      "epoch:12, \t lr:[0.00035999999999999997], \n",
      " train loss:0.015604525478482246, \t val loss:0.023872291058057455, \n",
      " train acc:0.99492, \t\t\t val acc:0.9931 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:13, \t lr:[0.00035999999999999997], \n",
      " train loss:0.014836285055037588, \t val loss:0.028425191220766283, \n",
      " train acc:0.99504, \t\t\t val acc:0.9927 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:14, \t lr:[0.00021599999999999996], \n",
      " train loss:0.014224205153053627, \t val loss:0.026901177880412432, \n",
      " train acc:0.99536, \t\t\t val acc:0.9926 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.023872 --> 0.023494).  Saving model ...\n",
      "epoch:15, \t lr:[0.00021599999999999996], \n",
      " train loss:0.011829510488286614, \t val loss:0.023493880187231114, \n",
      " train acc:0.99614, \t\t\t val acc:0.9932 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:16, \t lr:[0.00021599999999999996], \n",
      " train loss:0.011269221036611125, \t val loss:0.024816696498519742, \n",
      " train acc:0.99644, \t\t\t val acc:0.9934 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:17, \t lr:[0.00021599999999999996], \n",
      " train loss:0.010117102411687375, \t val loss:0.02408519632673124, \n",
      " train acc:0.99666, \t\t\t val acc:0.9938 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:18, \t lr:[0.00021599999999999996], \n",
      " train loss:0.010708412420935929, \t val loss:0.025382454916404094, \n",
      " train acc:0.99636, \t\t\t val acc:0.9929 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:19, \t lr:[0.00012959999999999998], \n",
      " train loss:0.009895987003184855, \t val loss:0.02574030061067897, \n",
      " train acc:0.99682, \t\t\t val acc:0.993 \n",
      "\n",
      "\n",
      "Validation loss decreased (0.023494 --> 0.022297).  Saving model ...\n",
      "epoch:20, \t lr:[0.00012959999999999998], \n",
      " train loss:0.008220956607861445, \t val loss:0.02229705524621677, \n",
      " train acc:0.9973, \t\t\t val acc:0.9937 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 1 out of 15\n",
      "epoch:21, \t lr:[0.00012959999999999998], \n",
      " train loss:0.008803045047498308, \t val loss:0.023991879515373876, \n",
      " train acc:0.99714, \t\t\t val acc:0.9936 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 2 out of 15\n",
      "epoch:22, \t lr:[0.00012959999999999998], \n",
      " train loss:0.007485337612484582, \t val loss:0.02408388932746893, \n",
      " train acc:0.99742, \t\t\t val acc:0.9938 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 3 out of 15\n",
      "epoch:23, \t lr:[0.00012959999999999998], \n",
      " train loss:0.007426839662035927, \t val loss:0.023868900394903903, \n",
      " train acc:0.99778, \t\t\t val acc:0.9937 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 4 out of 15\n",
      "epoch:24, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.007852967874649912, \t val loss:0.024129212538227147, \n",
      " train acc:0.99728, \t\t\t val acc:0.994 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 5 out of 15\n",
      "epoch:25, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.006333646636484191, \t val loss:0.02327942056431857, \n",
      " train acc:0.99786, \t\t\t val acc:0.9939 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 6 out of 15\n",
      "epoch:26, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.005939127060333267, \t val loss:0.02550038395120646, \n",
      " train acc:0.99796, \t\t\t val acc:0.9939 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 7 out of 15\n",
      "epoch:27, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.005802851562174037, \t val loss:0.024847808861792147, \n",
      " train acc:0.99812, \t\t\t val acc:0.9935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 8 out of 15\n",
      "epoch:28, \t lr:[7.775999999999999e-05], \n",
      " train loss:0.005441342087164521, \t val loss:0.02489520642768257, \n",
      " train acc:0.99796, \t\t\t val acc:0.9935 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 9 out of 15\n",
      "epoch:29, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0048850911674276, \t val loss:0.026974928571187776, \n",
      " train acc:0.99862, \t\t\t val acc:0.9937 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 10 out of 15\n",
      "epoch:30, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.005077075793490512, \t val loss:0.02502191957500909, \n",
      " train acc:0.99836, \t\t\t val acc:0.9939 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 11 out of 15\n",
      "epoch:31, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.0050687415077490736, \t val loss:0.02514749086962256, \n",
      " train acc:0.99824, \t\t\t val acc:0.9937 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 12 out of 15\n",
      "epoch:32, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.004865502897114493, \t val loss:0.02397445786546741, \n",
      " train acc:0.9984, \t\t\t val acc:0.9941 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 13 out of 15\n",
      "epoch:33, \t lr:[4.665599999999999e-05], \n",
      " train loss:0.004673555082501843, \t val loss:0.02620182324526104, \n",
      " train acc:0.99842, \t\t\t val acc:0.9942 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 14 out of 15\n",
      "epoch:34, \t lr:[2.7993599999999992e-05], \n",
      " train loss:0.00466640769615653, \t val loss:0.024568075123181914, \n",
      " train acc:0.9984, \t\t\t val acc:0.9944 \n",
      "\n",
      "\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "network_benign = Network().cuda()\n",
    "network_benign.train()\n",
    "epochs = 60\n",
    "    \n",
    "opt = torch.optim.Adam(network_benign.parameters(), lr=0.001)\n",
    "scheduler = StepLR(opt, step_size=5, gamma=0.6)\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True, path = 'checkpoint_-1.pt')\n",
    "    \n",
    "network_benign, all_train_losses, all_valid_losses = train(-1,network_benign, epochs, dataloader_train_benign, dataloader_val_benign, opt, scheduler, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all saved digit specific classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_0 = Network_Digits().cuda()\n",
    "network_0.load_state_dict(torch.load('Network_0.pt'))\n",
    "network_1 = Network_Digits().cuda()\n",
    "network_1.load_state_dict(torch.load('Network_1.pt'))\n",
    "network_2 = Network_Digits().cuda()\n",
    "network_2.load_state_dict(torch.load('Network_2.pt'))\n",
    "network_3 = Network_Digits().cuda()\n",
    "network_3.load_state_dict(torch.load('Network_3.pt'))\n",
    "network_4 = Network_Digits().cuda()\n",
    "network_4.load_state_dict(torch.load('Network_4.pt'))\n",
    "network_5 = Network_Digits().cuda()\n",
    "network_5.load_state_dict(torch.load('Network_5.pt'))\n",
    "network_6 = Network_Digits().cuda()\n",
    "network_6.load_state_dict(torch.load('Network_6.pt'))\n",
    "network_7 = Network_Digits().cuda()\n",
    "network_7.load_state_dict(torch.load('Network_7.pt'))\n",
    "network_8 = Network_Digits().cuda()\n",
    "network_8.load_state_dict(torch.load('Network_8.pt'))\n",
    "network_9 = Network_Digits().cuda()\n",
    "network_9.load_state_dict(torch.load('Network_9.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = data_test(path_test, filenames_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_full(network_benign, network_0, network_1, network_2, network_3, network_4, network_5, network_6, network_7, network_8, network_9, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.Series(preds, index = filenames_test).to_csv(\"test_predictions_11_networks.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets compare to our first solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_preds = pd.read_csv('predictions_1.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000b827c1a2b47afb746abfd5d92534d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0015f48c0f70464e9ad0d4d7877b7522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>001765b6faf241da8ed6552cfe4a85ec</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0018bf542c7a421ea1ff20e17c590005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>001ae337cafa493e91c1d9ae41470a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>ffe19bfb6e244dedb624d3f27ad4afa4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>ffe6282504da4c51bbd18d6d85ddb7c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>fff30413e8284b9f8474ff47d2d20532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>fff933ad67244db981c2d2626d436ef3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>fffe64cf37a248bfa3d0420a7b7cfa93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0  1\n",
       "0     000b827c1a2b47afb746abfd5d92534d  1\n",
       "1     0015f48c0f70464e9ad0d4d7877b7522  0\n",
       "2     001765b6faf241da8ed6552cfe4a85ec  0\n",
       "3     0018bf542c7a421ea1ff20e17c590005  0\n",
       "4     001ae337cafa493e91c1d9ae41470a9d  0\n",
       "...                                ... ..\n",
       "9995  ffe19bfb6e244dedb624d3f27ad4afa4  1\n",
       "9996  ffe6282504da4c51bbd18d6d85ddb7c9  1\n",
       "9997  fff30413e8284b9f8474ff47d2d20532  0\n",
       "9998  fff933ad67244db981c2d2626d436ef3  1\n",
       "9999  fffe64cf37a248bfa3d0420a7b7cfa93  0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_preds_list = []\n",
    "for i in first_preds.iloc[:,1]:\n",
    "    first_preds_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597994257489679"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(first_preds_list,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "008c55b72a4748f5b5256a6aa51b7b57 first  0 second  1\n",
      "01369bb36b4946178114c69341108186 first  0 second  1\n",
      "01f935d3eb2d4284a14900479c0c24ba first  0 second  1\n",
      "02d4ad964ffa4c14a52c585c6a638530 first  0 second  1\n",
      "03652bd5498046e789f167e1b150b78c first  0 second  1\n",
      "03ad28d68234461c900dd39d7abc3e05 first  0 second  1\n",
      "040a1961f677470e9e988d3158477089 first  0 second  1\n",
      "043e071e499c4faf938df2be4590b753 first  0 second  1\n",
      "04e311563b94442f8ec2735b8444d585 first  0 second  1\n",
      "05154da399b94ddba37cf9725688db83 first  0 second  1\n",
      "05c94866082f42bdb291909c30a722f0 first  0 second  1\n",
      "0663af55cc354cbf9edb87c7aa947b43 first  0 second  1\n",
      "06dc420d7d3d44ddb61cf128f8bcb28b first  0 second  1\n",
      "070acb87caf440e3be69993fea16671b first  0 second  1\n",
      "070c51704cde47c6ace313c8bbfcc780 first  0 second  1\n",
      "07ff4156622343388c57b0e804a5b286 first  0 second  1\n",
      "09d9e446a6f14e67a92504090462a9a0 first  0 second  1\n",
      "0b319257afc1455594d95aa4f3288be9 first  0 second  1\n",
      "0b4bc37a48004833980b4a7b31f65864 first  0 second  1\n",
      "0cf41f31ea9b4a1ba0121215c3cbfeba first  0 second  1\n",
      "0dc353725e4942e9a388364b74d7bd9b first  0 second  1\n",
      "0ee8ff44c8cd40399834886f91541aee first  0 second  1\n",
      "106c234439894c7596eec9996933327d first  0 second  1\n",
      "108489c5a6bb4277967505c3a14cf59a first  0 second  1\n",
      "108f2006c4a34ea1bf1676224d0ad8cf first  0 second  1\n",
      "10b3600149d2401e81f9b1d9dca8ec17 first  0 second  1\n",
      "111a95848ee14ad49f58ed6501dd73cd first  0 second  1\n",
      "1123920f61074e0890a4a767a616711c first  0 second  1\n",
      "11aecd3b50154928a3066043051d282a first  0 second  1\n",
      "11b0023eda5c49ea8c9bee70b2197a0d first  0 second  1\n",
      "1204152465e24d7f970358c3b550c97a first  0 second  1\n",
      "1244430faffb4aafa228fa99b4ff9ce1 first  0 second  1\n",
      "12462214610d4792833b1011bfa4bf30 first  0 second  1\n",
      "12aa0c0049d3491e9ad42ae514f99143 first  0 second  1\n",
      "12f7fc44c7ab41c6b1e13ef3b1f5c98e first  0 second  1\n",
      "1438234708f049d59e889d5b6e57628d first  0 second  1\n",
      "14d8f710158b47bb9b9b238a397395c3 first  0 second  1\n",
      "14e3c13a09604eb08cd5539848a4231f first  0 second  1\n",
      "15376ec95987442d9478c191c7fa50fb first  0 second  1\n",
      "15af052f9ee746e6a1d1ef5a850290af first  0 second  1\n",
      "15cbd2331da04057be433f54b8484d62 first  0 second  1\n",
      "164c28293748416f8921165b0783bd63 first  0 second  1\n",
      "166668f4f5b5425ba5957c71e245acee first  0 second  1\n",
      "18301325f9f44aca89997d6149ee826b first  0 second  1\n",
      "18e75b338c874468922e2bc10fbec077 first  0 second  1\n",
      "1ad61b6a117941a4b753aceec3c12a1a first  0 second  1\n",
      "1b303c8ea6f74ddea1f06d3b76b8c878 first  0 second  1\n",
      "1b4daddbb126418fb235c60661dcad98 first  0 second  1\n",
      "1ba0e481ee8f44e7b3551c8012c10470 first  0 second  1\n",
      "1ba1a611d61f445f8bfc6bf4aa2dca4f first  0 second  1\n",
      "1ba2335230154c90908ff895298e60a8 first  0 second  1\n",
      "1bd36352b1014f7b9aa64cbaf58c7f50 first  0 second  1\n",
      "1cf7ae41c43440e1a64cd3df36d61535 first  0 second  1\n",
      "1cf8a3afb3d5405192e103bb7ebd7d9c first  0 second  1\n",
      "1dc2f492b85143609b95488c54c45482 first  0 second  1\n",
      "2021199b7fa14c68aeacfc1b4d8e1b51 first  0 second  1\n",
      "207157992f704ff4aa7c330cda8f6e55 first  0 second  1\n",
      "20768bfdc1a344fca5df6fd5da6c14af first  0 second  1\n",
      "208b13385c464741bde3f74f8db12c09 first  0 second  1\n",
      "210a2c44cf9443aabe99ac858a40aa63 first  0 second  1\n",
      "213576157fec4f8dbd7628d2d1a8a4c1 first  0 second  1\n",
      "21e6abe97b0347c8a8e42a41eba68436 first  0 second  1\n",
      "22e3acd311ae4e9c945083fd63e72b2e first  0 second  1\n",
      "235d65baa1e948c88ed45ab72d753813 first  0 second  1\n",
      "236ea8ddfcfc4bd6a8654f82ce222b9a first  0 second  1\n",
      "237cbd4ce80b4eb493bf37c3470cf177 first  1 second  0\n",
      "263bcc48c7d9437091d9b4d7bb5f63cb first  0 second  1\n",
      "2708b702d3494a6a87ab8bd6a560d71a first  0 second  1\n",
      "271c30228e874a8199fa75f32147ed63 first  0 second  1\n",
      "27602906fb6f4f9684a6d059c27804a5 first  1 second  0\n",
      "27bedc27502b4cd7a4dfa3c2a98de67b first  0 second  1\n",
      "27eff6049ada4ac08d0b4558299125c7 first  0 second  1\n",
      "2881f34537e645ce9b5c8e5c061d086e first  0 second  1\n",
      "2892bbbd8b764ae58036003ac07edf22 first  0 second  1\n",
      "28abab6253854088b9c025f0b111129f first  0 second  1\n",
      "2929c089ba664e2c9b52a9f251847f76 first  0 second  1\n",
      "29882220f01a4398b38bdcccfc0b9961 first  0 second  1\n",
      "2a482d8100d94bad89da25a00d3b4ddc first  0 second  1\n",
      "2a4c8c83363848f3892d22d9fb372802 first  0 second  1\n",
      "2b2faedaa83d48b087eae6f0d20f050e first  0 second  1\n",
      "2b9d4531c48d4070a604fe18cb413c5b first  0 second  1\n",
      "2c5166d054d54268aeb264533e55df80 first  0 second  1\n",
      "2c87d1b49a0e402480b68ad1981bc997 first  0 second  1\n",
      "2d11df6632f54a939da8a317996520a1 first  0 second  1\n",
      "2e01f4658119465a899e050ab87595bf first  0 second  1\n",
      "300952fddbf34ccf9e2c0919de205963 first  0 second  1\n",
      "30596c74b58c492ab3526332e67f8a13 first  0 second  1\n",
      "307fbb76244d4163b1ca322caaf68dbb first  0 second  1\n",
      "310d8fd7861a47ac95301008a55adafb first  0 second  1\n",
      "31888d9c979045729acb81e316628bef first  0 second  1\n",
      "32e33d66f7c74d32af19196b4296a8c1 first  0 second  1\n",
      "3374ad65e77e4dcdbd57b790e3328d6d first  0 second  1\n",
      "341f9e9559aa464fb3992570b3bcbc24 first  0 second  1\n",
      "34488082860d483b9b5bafb6c34179ad first  0 second  1\n",
      "35247356d6df4b899cbac354db8e6389 first  0 second  1\n",
      "3580c9ce25cb4a848dd69262ea167b8a first  0 second  1\n",
      "36c6d36542c94dd08f0395259c0d4542 first  0 second  1\n",
      "36ef4a37ed5345a582d6964ce39fbb94 first  0 second  1\n",
      "37e249957ab14abf89fc3296662eb83f first  0 second  1\n",
      "3aaf5c8b4104418f856770cb74bc1739 first  0 second  1\n",
      "3ab400f5359a402a8b7517a0045c2ac9 first  0 second  1\n",
      "3ae5a15e1b16422d8b57c08dacb99164 first  0 second  1\n",
      "3b1f3119b1a9467ca155adfc2cfdb9eb first  0 second  1\n",
      "3be542c7276240cd9bda2ef3e4c098a6 first  1 second  0\n",
      "3d29ff37227f45d0bc93a534f0ae7de1 first  0 second  1\n",
      "3ded90d2f32545d5bfa8e59111260c78 first  0 second  1\n",
      "3e2f46453b41468b924af4b578719138 first  0 second  1\n",
      "3ea48df2f1d943db9d2ef75d4ee47b70 first  0 second  1\n",
      "3ec0da6ca4ed4f48bac12d6397383edc first  0 second  1\n",
      "3eff31cf7322442b96ca13b9817db02e first  0 second  1\n",
      "3f0bc41d8c4b4530bc8dc85757f97e24 first  0 second  1\n",
      "3ff3ca1546d44f439ca279acc826894a first  0 second  1\n",
      "4067c951285c43cb848062867253a775 first  0 second  1\n",
      "4113b7ecd834429bb4607a8abc93d645 first  0 second  1\n",
      "42696ba5546e40e8aa6a61ad8955092c first  0 second  1\n",
      "42d273d02b2f4759a6d852f7e69d2390 first  0 second  1\n",
      "432ad3f63ef642e9948373aa9a04bac3 first  0 second  1\n",
      "43fb10aa4d2949ae90a41c497eeb484b first  0 second  1\n",
      "4408bf3e1ef64d028743ee7898915ad1 first  0 second  1\n",
      "4497ad2a332f419aaf7189a3de75cb8b first  0 second  1\n",
      "44cbfd9e40dd4bd698a4087fd80c783c first  0 second  1\n",
      "4500b90913544f50afb14fc9cefb840f first  0 second  1\n",
      "452377e7b69440b6be1c3b3f2bac95c4 first  0 second  1\n",
      "455713a052874e75bf9227cd8c5dc465 first  0 second  1\n",
      "465ac71b44814e2aa8a382aa863a0e32 first  0 second  1\n",
      "46a96f7783c04d8e8234b4193c6e6feb first  0 second  1\n",
      "46fc64590e2140cca2bcc1ccdb533a71 first  0 second  1\n",
      "477816e08b2649af906cd28eb51f0e28 first  0 second  1\n",
      "4877d4d3333c45449b4785e6244c4a8d first  0 second  1\n",
      "48c2658de54641959419286cf42ba8d8 first  0 second  1\n",
      "48e47955028f492f95b01958f8ce4f97 first  1 second  0\n",
      "494f930ef4c5423184180fa8cec7c694 first  0 second  1\n",
      "4a47a5066c7744c8b45420e3731cea00 first  0 second  1\n",
      "4b71af212b364cdaa7f95fe61e073809 first  0 second  1\n",
      "4b854d191d7e46aa95b2a13885f4befb first  0 second  1\n",
      "4ccae3da521c4275bd92109b485b16cf first  0 second  1\n",
      "4db0e57fa1874693a5eb3c4d73664c60 first  0 second  1\n",
      "4fb0e07a4a81499ebde191fef1978b34 first  0 second  1\n",
      "4fff69fdab494a0d929251c0b7daaec7 first  0 second  1\n",
      "51694e92ebec413f93bbe4267fbef2fa first  0 second  1\n",
      "51ae771d90d44e3d8fa21e89ea3f260a first  0 second  1\n",
      "51ef6978ca9c48d890937c8adfba2f15 first  0 second  1\n",
      "52eea91948ec4ce7b368721a16d54438 first  0 second  1\n",
      "53f99d28a91d484882f5afacd99146e2 first  0 second  1\n",
      "5484b480381948369bccc303a0d69ec1 first  0 second  1\n",
      "560ee238c6684ea9892b20db73c597c5 first  0 second  1\n",
      "566d45ac4b0f4117abb93d098b4e1c5b first  0 second  1\n",
      "59917a81d3cb4a309d39bdad507df565 first  0 second  1\n",
      "5a7ce381168b4c7586d1bfa46558d95b first  0 second  1\n",
      "5aca95b46e594247a46d0cb84dc0b032 first  0 second  1\n",
      "5b5998a340774a138666a0b2fb21e1b7 first  0 second  1\n",
      "5b7e58eed0ed4251a5e26d85f5774d52 first  0 second  1\n",
      "5b8f18d8e085418aa47273ec1dd8ab46 first  0 second  1\n",
      "5b9622d72c1145ac8c34a98a98ff1272 first  0 second  1\n",
      "5c1ce575daa74892911b622db5229e66 first  0 second  1\n",
      "5c406fc794484214ba021bb93f57da24 first  0 second  1\n",
      "5c694ba82f6c4c328c059bbc00499ce0 first  0 second  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f874d2c79c040d98428c3c0fd3daaae first  0 second  1\n",
      "5f9b38ce8a8f4ebc9d63e87265052b69 first  0 second  1\n",
      "6002d698cf5b4257a45b314bf91a92e9 first  0 second  1\n",
      "604f9af8194246a4b1a78ea54deffe84 first  0 second  1\n",
      "60935c65700d434d89f90bca8a50d4de first  0 second  1\n",
      "613d77fcea3a4a3e9de70da394b7dca4 first  0 second  1\n",
      "614ba6bd60ec4e62bb0d0a1e90adda6c first  0 second  1\n",
      "623ff5c2c8b749178eae2f8b4cc9a049 first  0 second  1\n",
      "6268db82addf47ba9a7dead1f652e956 first  0 second  1\n",
      "62c2117b7805454d950930040199e76c first  0 second  1\n",
      "633fa80d7c75461c87db887cd51c92e9 first  0 second  1\n",
      "6504b3108aba420cb3a87c46cd45716b first  0 second  1\n",
      "650e8cf9c0e7420d89e3cc3fcbf61c9f first  1 second  0\n",
      "65fb46e32cc0411d9d2280ffe1857095 first  0 second  1\n",
      "65fc80a3783542da8644871bc39cf421 first  0 second  1\n",
      "6643e4358e2b42238d5f9430032d58ff first  0 second  1\n",
      "66e42b3a51824e0cb0004cae57e24a82 first  0 second  1\n",
      "66faa8c9c9f94156bfa635fd68db3b31 first  0 second  1\n",
      "6709344a7cf04fd6987e06bf54153891 first  0 second  1\n",
      "685d88f1a60a43ceb37fbe2d97b83a35 first  0 second  1\n",
      "6884469559ef4183b7d6642a69a5304c first  0 second  1\n",
      "6919e7746e58447897b5a5d30779925c first  0 second  1\n",
      "695a3d04575c4e6eb401c9f34b81fc44 first  0 second  1\n",
      "698383ca62c84cdf86bb3cae2cae746e first  0 second  1\n",
      "6a86eb3adeaa4848907d2483ab6c7b76 first  0 second  1\n",
      "6b1b9807fb1a4212a24c4040df9f5646 first  0 second  1\n",
      "6b6e2c8d48c04b659fa897fe10a53022 first  0 second  1\n",
      "6b8b42b6aa0c4c6aa8b06c4a7da1e78b first  0 second  1\n",
      "6bd3d6fad6034dfd9b57efc04cf3912d first  0 second  1\n",
      "6bdd589a744f4504888dc7f068664649 first  0 second  1\n",
      "6be80d4c9dc045c5ab85056633b8055c first  0 second  1\n",
      "6c7cb10e4dd04c25b4a443e63804bca0 first  0 second  1\n",
      "6d1de4ed4bb5412ba8615291de969daa first  0 second  1\n",
      "6dcc1adcbe694d47852a4ff3f805ef38 first  0 second  1\n",
      "6dd9610b7d1a42018325534600ce51ef first  0 second  1\n",
      "6e2ffab3ef48496c835c9f2bb7469131 first  0 second  1\n",
      "6e70265b5c764c88b90506adf834519c first  0 second  1\n",
      "6f5f4810644447b8bbeb282d518d2afd first  0 second  1\n",
      "6fd4e3c4e5e644d7891c0a943b20b1f2 first  0 second  1\n",
      "7020164d77a24932b5121628a1b3e2bb first  0 second  1\n",
      "7026e6cadea54b348836f9a3b39055f1 first  0 second  1\n",
      "7043cbd91f1b4ec5a17aa2aa08e157da first  0 second  1\n",
      "706b9706fa3b423e83f1c605a7b4076f first  0 second  1\n",
      "70740eae61774edab6476514c81e9065 first  0 second  1\n",
      "70921e6930c74ec5afbcfaa83c4eb2df first  0 second  1\n",
      "7097e7bca1104a49b29a68f1dd833648 first  0 second  1\n",
      "70e50573f7414ed9b33afb99e10da150 first  0 second  1\n",
      "716876c08ef64b2892e0d04efa9044ba first  0 second  1\n",
      "7179d4f123a24f5f9fd6e772579607fe first  0 second  1\n",
      "71afa54660cd4a40bb4ffb0648c45392 first  0 second  1\n",
      "71b8c5122fb24326bb6eab7c673925f5 first  0 second  1\n",
      "728c4d5790b4445f85b6092309e1d880 first  0 second  1\n",
      "72ae2cb015354a3b99df028b8af1fe7e first  0 second  1\n",
      "72b75f79d095434f9d140728e5ecf338 first  0 second  1\n",
      "7388eee84763436c92055de742afb28d first  0 second  1\n",
      "73bc5ac0fdd54fd0b8e52893617899eb first  0 second  1\n",
      "73d05bcef0f34d148ae69e462c84f851 first  0 second  1\n",
      "741618218956416b9e77b1c3bd00e1a0 first  0 second  1\n",
      "74b41d09bf16474a8b1e326ac479c79a first  0 second  1\n",
      "74ce5a45f70d4c7cb840cd5ebe07b3eb first  0 second  1\n",
      "767c01b830dc489e87a200d36ec6947e first  0 second  1\n",
      "76ca7eecab7940ea813951e321bad110 first  0 second  1\n",
      "77e47ba19cef4dcba1f00e349b914aa5 first  0 second  1\n",
      "78806785b9d34f24b33a699505ae4611 first  0 second  1\n",
      "791e170ab5234bf4a4d6b241480f0449 first  0 second  1\n",
      "79d8c26890f247f694b844ab926e5461 first  0 second  1\n",
      "7aca4aa12d1f4504933e18404f3258d4 first  0 second  1\n",
      "7b241464422a462684ed849c5614f64a first  0 second  1\n",
      "7b2a8fd5285543219be1d729b679eef0 first  1 second  0\n",
      "7c3ded186b0f4ef38e02d36a69acfe25 first  0 second  1\n",
      "7c6a6a58c6d744488279841f46e3a1c4 first  0 second  1\n",
      "7ce1ef9fe74a4a55b1de999a8b3450af first  0 second  1\n",
      "7e1c9c027af74942bd5a8339596a83c1 first  0 second  1\n",
      "7e614628d88f486a9539393b350719ec first  0 second  1\n",
      "7e6e8f01036443649490d7367838033a first  0 second  1\n",
      "7f18033755244ccd9bcae728d88f41d4 first  0 second  1\n",
      "805306de547e4eb9b31aedb8c2f75473 first  0 second  1\n",
      "8160b33c3c784806a61c279e92c35c48 first  0 second  1\n",
      "81983b528de74d94b3ee58cb27137dc5 first  0 second  1\n",
      "81e2c99e693448cbac509f6db69be109 first  0 second  1\n",
      "825163e37e2840cca51cec8c388dc6ac first  0 second  1\n",
      "82c0c6f403b143b5b3b6c09e85cc7e3b first  0 second  1\n",
      "82f1b26e406d4d6e80055f87e18f5f78 first  0 second  1\n",
      "83d66d02429a4b948b2349eca3ed2d56 first  0 second  1\n",
      "848f897526b04f4c85cfd27c4f99c8ed first  0 second  1\n",
      "8529283cef3e40b69e521103f7c8ee3d first  0 second  1\n",
      "8579a1bfef5e48088f47434121acb4e1 first  0 second  1\n",
      "85b1e1a3e7204c108ceac57f23b16769 first  1 second  0\n",
      "85fbee1eb31d4d9fabadd6c83fb13859 first  0 second  1\n",
      "861db0ac37b74e0a8f699ffc7784c056 first  0 second  1\n",
      "866a188b726d41a6b6544b3b4893c236 first  0 second  1\n",
      "88376a16e24c41aca73f6f219f2ef8c3 first  0 second  1\n",
      "88e6b8be7b7447b29eb2f067baef3355 first  0 second  1\n",
      "8a0b9646339746ff8097aad4b01c8711 first  0 second  1\n",
      "8aec63cbcea34bf0ad1b2cee5ca3f263 first  0 second  1\n",
      "8b5a922c85ad4f488aab8d7b9800f056 first  0 second  1\n",
      "8b718e5c327b42a68e07c30b8b3a982a first  0 second  1\n",
      "8ba5e508579842b39cb6a1a30a1a67ca first  0 second  1\n",
      "8c8456b43b3f475e993b1eb9f4349b19 first  0 second  1\n",
      "8d5908786aa44e8cabd191ef6c96ceee first  0 second  1\n",
      "8df5e3d946d8485ba45238e062ba1bc6 first  0 second  1\n",
      "8e73982b246d4e9b98a73839535444b3 first  0 second  1\n",
      "8e87bf5bb6634a30a4af4d73f99c105f first  0 second  1\n",
      "91f894ea18da41a38980eb8c7a4433e5 first  0 second  1\n",
      "922df55570414750820d2fc86a8ca09a first  0 second  1\n",
      "92f0812056844ffe80ab61685cd7690b first  0 second  1\n",
      "932c26f075a2443c864d592a52fa5f7c first  0 second  1\n",
      "933c2c3c8cee48b7a0e9ac02bd0fb92f first  0 second  1\n",
      "93bb36714d6142cfa204e882b91ab148 first  0 second  1\n",
      "93bdd0e94d8a4a39baef711637ba0bb8 first  0 second  1\n",
      "94273d5bf4024dbf98079ad0964495b1 first  0 second  1\n",
      "944798f9700145409d89e9fdc84a31de first  0 second  1\n",
      "9453294ab58d4d188d9da3021a2325dc first  0 second  1\n",
      "94c805d9f53245b894173a765152aa8d first  0 second  1\n",
      "94f80092fa064ad48ca85d89cb882040 first  0 second  1\n",
      "95c85c5664b2447aa8b238b55e32412b first  0 second  1\n",
      "961bcf3a5e6349f09ebfc85acb6855fb first  0 second  1\n",
      "9758bbd3585f43f8a40dc0d4555d72f6 first  0 second  1\n",
      "977ef09c36494dab9f14893665c9369c first  0 second  1\n",
      "981b1ffb161c43e8a0c5f071ab6bd300 first  0 second  1\n",
      "9831d96477b7406d857fe3a57cc7833d first  0 second  1\n",
      "98717702fc0647c1a97953e122983415 first  0 second  1\n",
      "9a1883e4b66a4bf6ba39b79fd15cb2c0 first  0 second  1\n",
      "9a1fb34f6bba433b908264153bb4b999 first  0 second  1\n",
      "9a3a8136108e444cb414efa03f8e3603 first  0 second  1\n",
      "9ae69798cdb049a084f93797875e8ce7 first  0 second  1\n",
      "9b3847640d8b432da69371d53341ef03 first  0 second  1\n",
      "9c1373bc5f4f47949629b656de113e0d first  0 second  1\n",
      "9c2248e548c1478992cacd7c6c09ae42 first  0 second  1\n",
      "9ceb72463c1b4071b41b085cffe89a05 first  0 second  1\n",
      "9cfe778d4eed41c4b1b7be5821c76e63 first  0 second  1\n",
      "9d45de589201498b94c64ac417ba559e first  0 second  1\n",
      "9d65cb6abb264d83ae6ac9e394d7a5e5 first  0 second  1\n",
      "9ddc13d07c1048c3b6d196f36e83fbca first  0 second  1\n",
      "9df7c5b753ec4be1ba0d549b959ed491 first  0 second  1\n",
      "9e37abea5a48413aa5a6276fdef5c225 first  0 second  1\n",
      "9e98f069324e4e38a57d034828c76d07 first  0 second  1\n",
      "9ebcfaae14aa49888d3a1a88502f53d0 first  0 second  1\n",
      "9f594773edb7480090be295a654b47d0 first  0 second  1\n",
      "9f9f2992b00b4733a5b8f965c466323e first  0 second  1\n",
      "9fa14f394a3448db8aa4cc5c511d4c49 first  1 second  0\n",
      "9fe37ab90351415894ed98def53ee926 first  0 second  1\n",
      "a1c4dc098f9a463f9ddab905003e0724 first  0 second  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_diff = 0\n",
    "\n",
    "for i, value in enumerate(first_preds_list):\n",
    "    if(first_preds_list[i] != preds[i]):\n",
    "        total_diff += 1\n",
    "        print(filenames_test[i], \"first \", first_preds_list[i], \"second \", preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_val = DataLoader(val_set_benign, batch_size = 1) \n",
    "\n",
    "# network = Network_Digits().cuda()\n",
    "# network.load_state_dict(torch.load('checkpoint_{}.pt'.format(0)))\n",
    "# preds_val = predict_full(network, network_0, network_1, network_2, network_3, network_4, network_5, network_6, network_7, network_8, network_9, dataloader_val)\n",
    "\n",
    "# f1_score(val_set[:][1],preds_val,average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = data_test(path_test, filenames_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  14.9546,  193.4244, -279.0008, -296.6172, -332.4962, -304.6013,\n",
      "         -212.8574, -314.0970, -244.9554, -283.4384]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5e357902e685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_10\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnetwork_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-5ac501ef9062>\u001b[0m in \u001b[0;36mpredict_10\u001b[1;34m(network_0, network_1, network_2, network_3, network_4, network_5, network_6, network_7, network_8, network_9, dataloader)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_binary\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#         preds.append(output_binary.max(1)[1].item())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "preds = predict_10( network_0, network_1, network_2, network_3, network_4, network_5, network_6, network_7, network_8, network_9, dataloader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds, index = filenames_test).to_csv(\"test_predictions_many_networks.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(all_train_losses)+1),all_train_losses, label='Training Loss')\n",
    "plt.plot(range(1,len(all_valid_losses)+1),all_valid_losses,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "# minposs = valid_loss.index(min(valid_loss))+1 \n",
    "# plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 0.01) # consistent scale\n",
    "plt.xlim(1, len(all_train_losses)) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965407869417329"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_val_pred_0 = DataLoader(val_set_0, batch_size = 1) \n",
    "\n",
    "network = Network_Digits().cuda()\n",
    "network.load_state_dict(torch.load('checkpoint_{}.pt'.format(0)))\n",
    "preds_val_0 = predict(network, dataloader_val_pred_0)\n",
    "\n",
    "balanced_accuracy_score(val_set_0[:][1],preds_val_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
