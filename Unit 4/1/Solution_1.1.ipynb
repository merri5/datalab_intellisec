{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import androguard\n",
    "from androguard.misc import AnalyzeAPK, APK\n",
    "\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_APK(filename, path):\n",
    "    dict_entry = {}\n",
    "    file = os.path.join(path, filename)\n",
    "    try:\n",
    "        a = APK(file)\n",
    "    except:\n",
    "        print(filename)\n",
    "        dict_entry[filename] = []\n",
    "        return dict_entry\n",
    "    \n",
    "\n",
    "    features = a.get_activities()\n",
    "    features = features + a.get_permissions()\n",
    "    features = features + a.get_services()\n",
    "    features = features + a.get_providers()\n",
    "    if(a.is_multidex()): features = features + ['is_multidex']\n",
    "    else: features = features + ['is_not_multidex']\n",
    "    if(a.is_valid_APK()): features = features + ['is_valid_APK']\n",
    "    else: features = features + ['is_not_valid_APK']\n",
    "\n",
    "    dict_entry[filename] = features\n",
    "\n",
    "    return dict_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_features(data_dict):\n",
    "    unique_tags_set = set({})\n",
    "\n",
    "    for key in data_dict:\n",
    "        unique_tags_set.update(set(data_dict[key]))\n",
    "    \n",
    "    unique_tags = list(unique_tags_set)\n",
    "    return unique_tags\n",
    "\n",
    "\n",
    "def get_features(list_features, unique_features):\n",
    "    features = np.zeros(len(unique_features))\n",
    "    for feature in list_features:\n",
    "        if feature in unique_features:\n",
    "            ind = unique_features.index(feature)\n",
    "            features[ind] = 1\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(os.getcwd(), \"ch01-train\")\n",
    "filenames_train = os.listdir(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 987 ms, total: 12.7 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_train_list = (Parallel(n_jobs = -1)(delayed(analyze_APK)(filename, path_train) for filename in filenames_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {}\n",
    "\n",
    "for entry in data_train_list:\n",
    "    key = list(entry.keys())[0]\n",
    "    data_train[key] = entry[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_features = get_unique_features(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_train:\n",
    "    data_train[key] = get_features(data_train[key], unique_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train = pd.DataFrame.from_dict(data_train, orient='index', columns = unique_features)\n",
    "dataframe_train[\"y\"] = pd.Series(dataframe_train.index).apply(lambda z: int(z[-1])).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train.to_csv(\"train_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.path.join(os.getcwd(), \"ch01-test\")\n",
    "filenames_test = os.listdir(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 10 instead\n",
      "Requested API Level could not be found, using 19 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 778 ms, total: 12.1 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_test_list = (Parallel(n_jobs = -1)(delayed(analyze_APK)(filename, path_test) for filename in filenames_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = {}\n",
    "\n",
    "for entry in data_test_list:\n",
    "    key = list(entry.keys())[0]\n",
    "    data_test[key] = entry[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_test:\n",
    "    data_test[key] = get_features(data_test[key], unique_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.DataFrame.from_dict(data_test, orient='index', columns = unique_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test.to_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train1 = pd.read_csv(\"train_features.csv\", index_col = 0)\n",
    "\n",
    "train = data_train1.drop([\"y\"], axis = 1).values\n",
    "\n",
    "labels = data_train1.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1 = pd.read_csv(\"test_features.csv\", index_col = 0)\n",
    "\n",
    "test = data_test1.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C':  [0.001, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]}  \n",
    "\n",
    "grid = GridSearchCV(LinearSVC(), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring= make_scorer(balanced_accuracy_score)) \n",
    "grid.fit(train, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearSVC = LinearSVC(C = 0.1)\n",
    "linearSVC.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_linearSVC = linearSVC.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds_linearSVC, index = data_test1.index).to_csv(\"test_predictions.csv\", header = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
